{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x775</th>\n",
       "      <th>x776</th>\n",
       "      <th>x777</th>\n",
       "      <th>x778</th>\n",
       "      <th>x779</th>\n",
       "      <th>x780</th>\n",
       "      <th>x781</th>\n",
       "      <th>x782</th>\n",
       "      <th>x783</th>\n",
       "      <th>x784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2  x3  x4  x5  x6  x7  x8  x9  ...  x775  x776  x777  x778  x779  \\\n",
       "0  6   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "1  5   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "2  7   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "3  9   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "4  5   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "\n",
       "   x780  x781  x782  x783  x784  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable=pd.read_csv(r\"E:\\cyber lab\\mnist_train_small - Copy.csv\")\n",
    "variable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x775</th>\n",
       "      <th>x776</th>\n",
       "      <th>x777</th>\n",
       "      <th>x778</th>\n",
       "      <th>x779</th>\n",
       "      <th>x780</th>\n",
       "      <th>x781</th>\n",
       "      <th>x782</th>\n",
       "      <th>x783</th>\n",
       "      <th>x784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2  x3  x4  x5  x6  x7  x8  x9  ...  x775  x776  x777  x778  x779  \\\n",
       "0  7   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "1  2   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "2  1   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "3  0   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "4  4   0   0   0   0   0   0   0   0   0  ...     0     0     0     0     0   \n",
       "\n",
       "   x780  x781  x782  x783  x784  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set=pd.read_csv(r\"E:\\cyber lab\\mnist_test - Copy.csv\")\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x775</th>\n",
       "      <th>x776</th>\n",
       "      <th>x777</th>\n",
       "      <th>x778</th>\n",
       "      <th>x779</th>\n",
       "      <th>x780</th>\n",
       "      <th>x781</th>\n",
       "      <th>x782</th>\n",
       "      <th>x783</th>\n",
       "      <th>x784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x775  x776  x777  x778  x779  \\\n",
       "0   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "1   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "2   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "3   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "4   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "\n",
       "   x780  x781  x782  x783  x784  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=variable.iloc[:,1:785]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    5\n",
       "2    7\n",
       "3    9\n",
       "4    5\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train=variable.iloc[:,0]\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x775</th>\n",
       "      <th>x776</th>\n",
       "      <th>x777</th>\n",
       "      <th>x778</th>\n",
       "      <th>x779</th>\n",
       "      <th>x780</th>\n",
       "      <th>x781</th>\n",
       "      <th>x782</th>\n",
       "      <th>x783</th>\n",
       "      <th>x784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4  x5  x6  x7  x8  x9  x10  ...  x775  x776  x777  x778  x779  \\\n",
       "0   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "1   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "2   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "3   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "4   0   0   0   0   0   0   0   0   0    0  ...     0     0     0     0     0   \n",
       "\n",
       "   x780  x781  x782  x783  x784  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=test_set.iloc[:,1:785]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7\n",
       "1    2\n",
       "2    1\n",
       "3    0\n",
       "4    4\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test=test_set.iloc[:,0]\n",
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "X_train=sc_X.fit_transform(X_train)\n",
    "X_test=sc_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034049</td>\n",
       "      <td>-0.022364</td>\n",
       "      <td>-0.013457</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034049</td>\n",
       "      <td>-0.022364</td>\n",
       "      <td>-0.013457</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034049</td>\n",
       "      <td>-0.022364</td>\n",
       "      <td>-0.013457</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034049</td>\n",
       "      <td>-0.022364</td>\n",
       "      <td>-0.013457</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034049</td>\n",
       "      <td>-0.022364</td>\n",
       "      <td>-0.013457</td>\n",
       "      <td>-0.014357</td>\n",
       "      <td>-0.011994</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       774       775  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.034049 -0.022364   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.034049 -0.022364   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.034049 -0.022364   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.034049 -0.022364   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.034049 -0.022364   \n",
       "\n",
       "        776       777       778       779  780  781  782  783  \n",
       "0 -0.013457 -0.014357 -0.011994 -0.009995  0.0  0.0  0.0  0.0  \n",
       "1 -0.013457 -0.014357 -0.011994 -0.009995  0.0  0.0  0.0  0.0  \n",
       "2 -0.013457 -0.014357 -0.011994 -0.009995  0.0  0.0  0.0  0.0  \n",
       "3 -0.013457 -0.014357 -0.011994 -0.009995  0.0  0.0  0.0  0.0  \n",
       "4 -0.013457 -0.014357 -0.011994 -0.009995  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=pd.DataFrame(X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>-0.021737</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>-0.021737</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>-0.021737</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>-0.021737</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031601</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>-0.021737</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...       774       775  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.031601 -0.028523   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.031601 -0.028523   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.031601 -0.028523   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.031601 -0.028523   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.031601 -0.028523   \n",
       "\n",
       "        776       777  778  779  780  781  782  783  \n",
       "0 -0.021737 -0.010001  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1 -0.021737 -0.010001  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2 -0.021737 -0.010001  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3 -0.021737 -0.010001  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4 -0.021737 -0.010001  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=pd.DataFrame(X_test)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1\n",
    "def initialize_parameters(lenw):\n",
    "    w=np.random.randn(1,lenw)\n",
    "    b=0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2\n",
    "def forward_prop(X,w,b):\n",
    "    z=np.dot(w,X)+b\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3\n",
    "def cost_function(z,Y):\n",
    "    m=Y.shape[1]\n",
    "    J=(1/(2*m))*np.sum(np.square(z-Y))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4\n",
    "def back_prop(X,Y,z):\n",
    "    m=Y.shape[1]\n",
    "    dz=(1/m)*(z-Y)\n",
    "    dw=np.dot(dz,X.T)\n",
    "    db=np.sum(dz)\n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5\n",
    "def gradient_descent_update(w,b,dw,db,learning_rate):\n",
    "    w=w-learning_rate*dw\n",
    "    b=b-learning_rate*db\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 6\n",
    "def linear_regression_model(X_train,Y_train,X_val,Y_val,learning_rate,epochs):\n",
    "    lenw=X_train.shape[0]\n",
    "    w,b=initialize_parameters(lenw)\n",
    "    costs_train=[]\n",
    "    m_train=Y_train.shape[1]\n",
    "    m_val=Y_val.shape[1]\n",
    "    for i in range(1,epochs+1):\n",
    "        z_train=forward_prop(X_train,w,b)\n",
    "        cost_train=cost_function(z_train,Y_train)\n",
    "        dw,db=back_prop(X_train,Y_train,z_train)\n",
    "        w,b=gradient_descent_update(w,b,dw,db,learning_rate)\n",
    "        \n",
    "        if i%10==0:\n",
    "            costs_train.append(cost_train)\n",
    "        \n",
    "       # MAE_train=(1/m_train)*np.sum(np.abs(z_train-Y_train))\n",
    "        \n",
    "        z_val=forward_prop(X_val,w,b)\n",
    "        cost_val=cost_function(z_val,Y_val)\n",
    "        #MAE_val=(1/m_val)*np.sum(np.abs(z_val-Y_val))\n",
    "        print('epochs '+str(i)+'/'+str(epochs)+':')\n",
    "        print('training cost '+str(cost_train)+'|'+'validation cost '+str(cost_val) )\n",
    "        print('b: '+str(b))\n",
    "    \n",
    "    plt.plot(costs_train)\n",
    "    plt.xlabel('iteration(per tens)')\n",
    "    plt.ylabel('training cost')\n",
    "    plt.title('learning rate' + str(learning_rate))\n",
    "    plt.show()\n",
    "    return w,b   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 20000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train=np.array([Y_train])\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=np.array([Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1/1000:\n",
      "training cost 278.202540120667|validation cost 245.15482647489716\n",
      "b: 0.03978477999999999\n",
      "epochs 2/1000:\n",
      "training cost 252.29920616929593|validation cost 225.8068608490013\n",
      "b: 0.079215475458\n",
      "epochs 3/1000:\n",
      "training cost 232.5652875156729|validation cost 210.16457185118375\n",
      "b: 0.11829523772642384\n",
      "epochs 4/1000:\n",
      "training cost 216.62075832819247|validation cost 197.02746268010816\n",
      "b: 0.15702719011065866\n",
      "epochs 5/1000:\n",
      "training cost 203.22921104101897|validation cost 185.7189578755579\n",
      "b: 0.1954144281186738\n",
      "epochs 6/1000:\n",
      "training cost 191.69306725241375|validation cost 175.8217392463172\n",
      "b: 0.2334600197084176\n",
      "epochs 7/1000:\n",
      "training cost 181.58336563558387|validation cost 167.05629933371344\n",
      "b: 0.27116700553301265\n",
      "epochs 8/1000:\n",
      "training cost 172.61453728003488|validation cost 159.22251188080327\n",
      "b: 0.3085383991837688\n",
      "epochs 9/1000:\n",
      "training cost 164.58357619223568|validation cost 152.16979047744658\n",
      "b: 0.3455771874310333\n",
      "epochs 10/1000:\n",
      "training cost 157.33874341798807|validation cost 145.78074785535736\n",
      "b: 0.38228633046289706\n",
      "epochs 11/1000:\n",
      "training cost 150.7623774750662|validation cost 139.96156185140617\n",
      "b: 0.4186687621217773\n",
      "epochs 12/1000:\n",
      "training cost 144.76078253606698|validation cost 134.63587943638575\n",
      "b: 0.4547273901388935\n",
      "epochs 13/1000:\n",
      "training cost 139.25787452939085|validation cost 129.7407149094733\n",
      "b: 0.49046509636665736\n",
      "epochs 14/1000:\n",
      "training cost 134.19094790776396|validation cost 125.22354975088402\n",
      "b: 0.5258847370089941\n",
      "epochs 15/1000:\n",
      "training cost 129.5077147340305|validation cost 121.04020282948588\n",
      "b: 0.560989142849614\n",
      "epochs 16/1000:\n",
      "training cost 125.16415222012405|validation cost 117.1532214193281\n",
      "b: 0.5957811194782524\n",
      "epochs 17/1000:\n",
      "training cost 121.12289063222951|validation cost 113.5306397773384\n",
      "b: 0.6302634475148959\n",
      "epochs 18/1000:\n",
      "training cost 117.3519780181888|validation cost 110.14500594255769\n",
      "b: 0.6644388828320134\n",
      "epochs 19/1000:\n",
      "training cost 113.82391687090531|validation cost 106.97260931537541\n",
      "b: 0.6983101567748085\n",
      "epochs 20/1000:\n",
      "training cost 110.51490242135144|validation cost 103.99286146985563\n",
      "b: 0.7318799763795126\n",
      "epochs 21/1000:\n",
      "training cost 107.40421363075178|validation cost 101.1877956619945\n",
      "b: 0.7651510245897349\n",
      "epochs 22/1000:\n",
      "training cost 104.47372175778766|validation cost 98.54165935725882\n",
      "b: 0.7981259604708862\n",
      "epochs 23/1000:\n",
      "training cost 101.70749064986795|validation cost 96.04058034192089\n",
      "b: 0.8308074194226954\n",
      "epochs 24/1000:\n",
      "training cost 99.09144935050381|validation cost 93.67229149978455\n",
      "b: 0.8631980133898335\n",
      "epochs 25/1000:\n",
      "training cost 96.6131222207055|validation cost 91.4259026762543\n",
      "b: 0.895300331070664\n",
      "epochs 26/1000:\n",
      "training cost 94.26140514293152|validation cost 89.29171056402294\n",
      "b: 0.9271169381241351\n",
      "epochs 27/1000:\n",
      "training cost 92.02637888990252|validation cost 87.2610394595175\n",
      "b: 0.9586503773748303\n",
      "epochs 28/1000:\n",
      "training cost 89.89915264398782|validation cost 85.32610721420251\n",
      "b: 0.9899031690161942\n",
      "epochs 29/1000:\n",
      "training cost 87.87173211163093|validation cost 83.479911850627\n",
      "b: 1.02087781081195\n",
      "epochs 30/1000:\n",
      "training cost 85.9369078061685|validation cost 81.71613520940508\n",
      "b: 1.0515767782957237\n",
      "epochs 31/1000:\n",
      "training cost 84.08815995291411|validation cost 80.02906069858696\n",
      "b: 1.0820025249688918\n",
      "epochs 32/1000:\n",
      "training cost 82.3195771616675|validation cost 78.41350277466636\n",
      "b: 1.1121574824966687\n",
      "epochs 33/1000:\n",
      "training cost 80.62578655755459|validation cost 76.86474622763794\n",
      "b: 1.1420440609024483\n",
      "epochs 34/1000:\n",
      "training cost 79.00189349405451|validation cost 75.37849369610872\n",
      "b: 1.1716646487604165\n",
      "epochs 35/1000:\n",
      "training cost 77.44342931705079|validation cost 73.95082012171227\n",
      "b: 1.2010216133864489\n",
      "epochs 36/1000:\n",
      "training cost 75.94630592476787|validation cost 72.57813307984938\n",
      "b: 1.2301173010273094\n",
      "epochs 37/1000:\n",
      "training cost 74.50677609017731|validation cost 71.25713810764238\n",
      "b: 1.2589540370481664\n",
      "epochs 38/1000:\n",
      "training cost 73.12139869125049|validation cost 69.98480829897083\n",
      "b: 1.2875341261184376\n",
      "epochs 39/1000:\n",
      "training cost 71.78700813917023|validation cost 68.758357557633\n",
      "b: 1.3158598523959835\n",
      "epochs 40/1000:\n",
      "training cost 70.50068741222752|validation cost 67.57521699861219\n",
      "b: 1.3439334797096592\n",
      "epochs 41/1000:\n",
      "training cost 69.25974419908684|validation cost 66.43301406852225\n",
      "b: 1.3717572517402432\n",
      "epochs 42/1000:\n",
      "training cost 68.06168973369695|validation cost 65.32955402302989\n",
      "b: 1.399333392199755\n",
      "epochs 43/1000:\n",
      "training cost 66.90421996876107|validation cost 64.26280345417585\n",
      "b: 1.4266641050091773\n",
      "epochs 44/1000:\n",
      "training cost 65.7851987880567|validation cost 63.23087560622971\n",
      "b: 1.4537515744745957\n",
      "epochs 45/1000:\n",
      "training cost 64.70264300215256|validation cost 62.232017256779194\n",
      "b: 1.4805979654617718\n",
      "epochs 46/1000:\n",
      "training cost 63.65470890892273|validation cost 61.2645969715739\n",
      "b: 1.507205423569162\n",
      "epochs 47/1000:\n",
      "training cost 62.63968023107164|validation cost 60.32709456834677\n",
      "b: 1.5335760752993965\n",
      "epochs 48/1000:\n",
      "training cost 61.655957268753475|validation cost 59.41809164733498\n",
      "b: 1.5597120282292318\n",
      "epochs 49/1000:\n",
      "training cost 60.70204712718084|validation cost 58.536263065247\n",
      "b: 1.5856153711779917\n",
      "epochs 50/1000:\n",
      "training cost 59.776554897579004|validation cost 57.68036924557429\n",
      "b: 1.6112881743745076\n",
      "epochs 51/1000:\n",
      "training cost 58.87817568553226|validation cost 56.84924923190512\n",
      "b: 1.6367324896225746\n",
      "epochs 52/1000:\n",
      "training cost 58.005687394153284|validation cost 56.04181440266267\n",
      "b: 1.6619503504649336\n",
      "epochs 53/1000:\n",
      "training cost 57.15794418096897|validation cost 55.25704277578204\n",
      "b: 1.6869437723457956\n",
      "epochs 54/1000:\n",
      "training cost 56.33387051726564|validation cost 54.49397384052777\n",
      "b: 1.711714752771918\n",
      "epochs 55/1000:\n",
      "training cost 55.53245578713145|validation cost 53.75170386115414\n",
      "b: 1.736265271472248\n",
      "epochs 56/1000:\n",
      "training cost 54.75274937078308|validation cost 53.02938160360599\n",
      "b: 1.760597290556145\n",
      "epochs 57/1000:\n",
      "training cost 53.993856163143136|validation cost 52.32620444209994\n",
      "b: 1.784712754670195\n",
      "epochs 58/1000:\n",
      "training cost 53.25493248418782|validation cost 51.64141480733926\n",
      "b: 1.8086135911536303\n",
      "epochs 59/1000:\n",
      "training cost 52.53518234243197|validation cost 50.974296942405736\n",
      "b: 1.832301710192363\n",
      "epochs 60/1000:\n",
      "training cost 51.83385401716249|validation cost 50.324173936127195\n",
      "b: 1.8557790049716512\n",
      "epochs 61/1000:\n",
      "training cost 51.150236928754616|validation cost 49.69040500701353\n",
      "b: 1.8790473518274036\n",
      "epochs 62/1000:\n",
      "training cost 50.48365876968083|validation cost 49.07238301375175\n",
      "b: 1.9021086103961398\n",
      "epochs 63/1000:\n",
      "training cost 49.83348287170951|validation cost 48.46953217080141\n",
      "b: 1.9249646237636142\n",
      "epochs 64/1000:\n",
      "training cost 49.19910578734114|validation cost 47.8813059498865\n",
      "b: 1.9476172186121181\n",
      "epochs 65/1000:\n",
      "training cost 48.57995506578761|validation cost 47.307185150171094\n",
      "b: 1.9700682053664702\n",
      "epochs 66/1000:\n",
      "training cost 47.9754872058014|validation cost 46.746676121673104\n",
      "b: 1.9923193783387085\n",
      "epochs 67/1000:\n",
      "training cost 47.38518576944051|validation cost 46.19930912803579\n",
      "b: 2.0143725158714942\n",
      "epochs 68/1000:\n",
      "training cost 46.80855964243632|validation cost 45.66463683617094\n",
      "b: 2.036229380480238\n",
      "epochs 69/1000:\n",
      "training cost 46.24514142824218|validation cost 45.142232921525675\n",
      "b: 2.057891718993964\n",
      "epochs 70/1000:\n",
      "training cost 45.6944859640977|validation cost 44.631690778831775\n",
      "b: 2.079361262694918\n",
      "epochs 71/1000:\n",
      "training cost 45.156168948569|validation cost 44.13262232918098\n",
      "b: 2.100639727456933\n",
      "epochs 72/1000:\n",
      "training cost 44.629785671030234|validation cost 43.64465691515328\n",
      "b: 2.1217288138825663\n",
      "epochs 73/1000:\n",
      "training cost 44.11494983445387|validation cost 43.16744027651264\n",
      "b: 2.1426302074390113\n",
      "epochs 74/1000:\n",
      "training cost 43.611292463684414|validation cost 42.70063359969272\n",
      "b: 2.163345578592804\n",
      "epochs 75/1000:\n",
      "training cost 43.11846089209792|validation cost 42.24391263492848\n",
      "b: 2.183876582943328\n",
      "epochs 76/1000:\n",
      "training cost 42.63611782020024|validation cost 41.796966875459546\n",
      "b: 2.2042248613551325\n",
      "epochs 77/1000:\n",
      "training cost 42.16394044030592|validation cost 41.35949879374233\n",
      "b: 2.224392040089072\n",
      "epochs 78/1000:\n",
      "training cost 41.70161962196765|validation cost 40.931223130069405\n",
      "b: 2.244379730932279\n",
      "epochs 79/1000:\n",
      "training cost 41.24885915330382|validation cost 40.511866229408625\n",
      "b: 2.264189531326982\n",
      "epochs 80/1000:\n",
      "training cost 40.80537503380151|validation cost 40.10116542264898\n",
      "b: 2.283823024498172\n",
      "epochs 81/1000:\n",
      "training cost 40.37089481456231|validation cost 39.69886844877759\n",
      "b: 2.3032817795801384\n",
      "epochs 82/1000:\n",
      "training cost 39.94515698230888|validation cost 39.30473291481727\n",
      "b: 2.322567351741875\n",
      "epochs 83/1000:\n",
      "training cost 39.52791038378929|validation cost 38.91852579062949\n",
      "b: 2.3416812823113724\n",
      "epochs 84/1000:\n",
      "training cost 39.118913687503955|validation cost 38.54002293593728\n",
      "b: 2.3606250988988013\n",
      "epochs 85/1000:\n",
      "training cost 38.71793487994164|validation cost 38.16900865714862\n",
      "b: 2.379400315518602\n",
      "epochs 86/1000:\n",
      "training cost 38.3247507937477|validation cost 37.805275291764985\n",
      "b: 2.3980084327104865\n",
      "epochs 87/1000:\n",
      "training cost 37.93914666546361|validation cost 37.448622818346635\n",
      "b: 2.4164509376593633\n",
      "epochs 88/1000:\n",
      "training cost 37.56091572067172|validation cost 37.09885849017383\n",
      "b: 2.434729304314195\n",
      "epochs 89/1000:\n",
      "training cost 37.18985878455782|validation cost 36.755796490897126\n",
      "b: 2.4528449935057988\n",
      "epochs 90/1000:\n",
      "training cost 36.82578391606539|validation cost 36.41925761060899\n",
      "b: 2.4707994530635973\n",
      "epochs 91/1000:\n",
      "training cost 36.46850606396342|validation cost 36.08906894089613\n",
      "b: 2.4885941179313313\n",
      "epochs 92/1000:\n",
      "training cost 36.11784674328357|validation cost 35.76506358754717\n",
      "b: 2.5062304102817423\n",
      "epochs 93/1000:\n",
      "training cost 35.77363373070586|validation cost 35.44708039969599\n",
      "b: 2.5237097396302346\n",
      "epochs 94/1000:\n",
      "training cost 35.43570077758285|validation cost 35.13496371427684\n",
      "b: 2.5410335029475255\n",
      "epochs 95/1000:\n",
      "training cost 35.103887339395875|validation cost 34.8285631147555\n",
      "b: 2.5582030847712924\n",
      "epochs 96/1000:\n",
      "training cost 34.77803832052916|validation cost 34.52773320318041\n",
      "b: 2.575219857316828\n",
      "epochs 97/1000:\n",
      "training cost 34.4580038333341|validation cost 34.23233338467151\n",
      "b: 2.5920851805867082\n",
      "epochs 98/1000:\n",
      "training cost 34.14363897053367|validation cost 33.942227663531256\n",
      "b: 2.6088004024794866\n",
      "epochs 99/1000:\n",
      "training cost 33.834803590088825|validation cost 33.65728445022373\n",
      "b: 2.625366858897419\n",
      "epochs 100/1000:\n",
      "training cost 33.53136211171461|validation cost 33.37737637852436\n",
      "b: 2.641785873853232\n",
      "epochs 101/1000:\n",
      "training cost 33.23318332429398|validation cost 33.102380132193844\n",
      "b: 2.658058759575938\n",
      "epochs 102/1000:\n",
      "training cost 32.94014020349251|validation cost 32.83217628057785\n",
      "b: 2.6741868166157126\n",
      "epochs 103/1000:\n",
      "training cost 32.652109738928154|validation cost 32.566649122576855\n",
      "b: 2.690171333947833\n",
      "epochs 104/1000:\n",
      "training cost 32.36897277029707|validation cost 32.30568653847116\n",
      "b: 2.706013589075697\n",
      "epochs 105/1000:\n",
      "training cost 32.09061383189945|validation cost 32.04917984912236\n",
      "b: 2.7217148481329234\n",
      "epochs 106/1000:\n",
      "training cost 31.816921005048574|validation cost 31.797023682106612\n",
      "b: 2.7372763659845405\n",
      "epochs 107/1000:\n",
      "training cost 31.54778577788339|validation cost 31.549115844366085\n",
      "b: 2.752699386327278\n",
      "epochs 108/1000:\n",
      "training cost 31.283102912137867|validation cost 31.305357200993676\n",
      "b: 2.7679851417889654\n",
      "epochs 109/1000:\n",
      "training cost 31.022770316451755|validation cost 31.06565155979279\n",
      "b: 2.7831348540270437\n",
      "epochs 110/1000:\n",
      "training cost 30.766688925835858|validation cost 30.829905561278004\n",
      "b: 2.798149733826203\n",
      "epochs 111/1000:\n",
      "training cost 30.514762586931244|validation cost 30.598028573805014\n",
      "b: 2.81303098119515\n",
      "epochs 112/1000:\n",
      "training cost 30.26689794872624|validation cost 30.3699325935398\n",
      "b: 2.8277797854625133\n",
      "epochs 113/1000:\n",
      "training cost 30.023004358417793|validation cost 30.14553214899506\n",
      "b: 2.842397325371897\n",
      "epochs 114/1000:\n",
      "training cost 29.782993762124292|validation cost 29.924744209880775\n",
      "b: 2.8568847691760872\n",
      "epochs 115/1000:\n",
      "training cost 29.546780610176455|validation cost 29.70748810003171\n",
      "b: 2.87124327473042\n",
      "epochs 116/1000:\n",
      "training cost 29.314281766730893|validation cost 29.493685414190278\n",
      "b: 2.885473989585319\n",
      "epochs 117/1000:\n",
      "training cost 29.08541642346716|validation cost 29.2832599384369\n",
      "b: 2.89957805107801\n",
      "epochs 118/1000:\n",
      "training cost 28.860106017144794|validation cost 29.076137574073744\n",
      "b: 2.9135565864234154\n",
      "epochs 119/1000:\n",
      "training cost 28.638274150811057|validation cost 28.87224626477948\n",
      "b: 2.9274107128042473\n",
      "epochs 120/1000:\n",
      "training cost 28.41984651846302|validation cost 28.671515926864018\n",
      "b: 2.9411415374602896\n",
      "epochs 121/1000:\n",
      "training cost 28.20475083298047|validation cost 28.47387838246315\n",
      "b: 2.954750157776893\n",
      "epochs 122/1000:\n",
      "training cost 27.992916757156916|validation cost 28.27926729552215\n",
      "b: 2.9682376613726786\n",
      "epochs 123/1000:\n",
      "training cost 27.78427583766715|validation cost 28.08761811042714\n",
      "b: 2.981605126186462\n",
      "epochs 124/1000:\n",
      "training cost 27.578761441819353|validation cost 27.898867993151054\n",
      "b: 2.9948536205634024\n",
      "epochs 125/1000:\n",
      "training cost 27.37630869694907|validation cost 27.71295577478911\n",
      "b: 3.007984203340388\n",
      "epochs 126/1000:\n",
      "training cost 27.176854432320887|validation cost 27.529821897366055\n",
      "b: 3.0209979239306586\n",
      "epochs 127/1000:\n",
      "training cost 26.980337123411744|validation cost 27.349408361804404\n",
      "b: 3.0338958224076755\n",
      "epochs 128/1000:\n",
      "training cost 26.786696838457214|validation cost 27.17165867794893\n",
      "b: 3.0466789295882473\n",
      "epochs 129/1000:\n",
      "training cost 26.59587518714886|validation cost 26.996517816549225\n",
      "b: 3.059348267114912\n",
      "epochs 130/1000:\n",
      "training cost 26.407815271377647|validation cost 26.82393216310721\n",
      "b: 3.0719048475375894\n",
      "epochs 131/1000:\n",
      "training cost 26.22246163792403|validation cost 26.653849473501992\n",
      "b: 3.0843496743945047\n",
      "epochs 132/1000:\n",
      "training cost 26.03976023300132|validation cost 26.48621883130926\n",
      "b: 3.0966837422923934\n",
      "epochs 133/1000:\n",
      "training cost 25.859658358564076|validation cost 26.320990606737034\n",
      "b: 3.108908036985991\n",
      "epochs 134/1000:\n",
      "training cost 25.68210463029817|validation cost 26.158116417103756\n",
      "b: 3.121023535456816\n",
      "epochs 135/1000:\n",
      "training cost 25.507048937214073|validation cost 25.997549088788865\n",
      "b: 3.13303120599125\n",
      "epochs 136/1000:\n",
      "training cost 25.334442402768865|validation cost 25.839242620589634\n",
      "b: 3.144932008257928\n",
      "epochs 137/1000:\n",
      "training cost 25.16423734744686|validation cost 25.68315214842171\n",
      "b: 3.1567268933844326\n",
      "epochs 138/1000:\n",
      "training cost 24.996387252732468|validation cost 25.529233911303916\n",
      "b: 3.168416804033311\n",
      "epochs 139/1000:\n",
      "training cost 24.830846726412332|validation cost 25.37744521857118\n",
      "b: 3.180002674477415\n",
      "epochs 140/1000:\n",
      "training cost 24.667571469147394|validation cost 25.227744418262244\n",
      "b: 3.191485430674566\n",
      "epochs 141/1000:\n",
      "training cost 24.506518242258455|validation cost 25.080090866631657\n",
      "b: 3.202865990341562\n",
      "epochs 142/1000:\n",
      "training cost 24.34764483667197|validation cost 24.93444489873797\n",
      "b: 3.2141452630275222\n",
      "epochs 143/1000:\n",
      "training cost 24.19091004297534|validation cost 24.790767800062635\n",
      "b: 3.2253241501865775\n",
      "epochs 144/1000:\n",
      "training cost 24.03627362253392|validation cost 24.649021779116463\n",
      "b: 3.236403545249917\n",
      "epochs 145/1000:\n",
      "training cost 23.883696279623976|validation cost 24.5091699409922\n",
      "b: 3.247384333697193\n",
      "epochs 146/1000:\n",
      "training cost 23.733139634538702|validation cost 24.37117626182459\n",
      "b: 3.2582673931272876\n",
      "epochs 147/1000:\n",
      "training cost 23.584566197625893|validation cost 24.23500556412027\n",
      "b: 3.269053593328455\n",
      "epochs 148/1000:\n",
      "training cost 23.437939344218666|validation cost 24.100623492922576\n",
      "b: 3.2797437963478315\n",
      "epochs 149/1000:\n",
      "training cost 23.29322329042194|validation cost 23.967996492777218\n",
      "b: 3.2903388565603358\n",
      "epochs 150/1000:\n",
      "training cost 23.15038306971955|validation cost 23.837091785467003\n",
      "b: 3.300839620736949\n",
      "epochs 151/1000:\n",
      "training cost 23.009384510368477|validation cost 23.707877348484956\n",
      "b: 3.31124692811239\n",
      "epochs 152/1000:\n",
      "training cost 22.870194213548316|validation cost 23.580321894216766\n",
      "b: 3.32156161045219\n",
      "epochs 153/1000:\n",
      "training cost 22.73277953223563|validation cost 23.454394849804736\n",
      "b: 3.3317844921191657\n",
      "epochs 154/1000:\n",
      "training cost 22.5971085507743|validation cost 23.330066337666878\n",
      "b: 3.341916390139305\n",
      "epochs 155/1000:\n",
      "training cost 22.463150065114345|validation cost 23.207307156645754\n",
      "b: 3.3519581142670654\n",
      "epochs 156/1000:\n",
      "training cost 22.330873563692844|validation cost 23.08608876376311\n",
      "b: 3.3619104670500883\n",
      "epochs 157/1000:\n",
      "training cost 22.200249208932206|validation cost 22.966383256557105\n",
      "b: 3.3717742438933427\n",
      "epochs 158/1000:\n",
      "training cost 22.07124781933159|validation cost 22.848163355980237\n",
      "b: 3.381550233122692\n",
      "epochs 159/1000:\n",
      "training cost 21.94384085212898|validation cost 22.731402389836997\n",
      "b: 3.3912392160479\n",
      "epochs 160/1000:\n",
      "training cost 21.818000386511955|validation cost 22.616074276741053\n",
      "b: 3.400841967025074\n",
      "epochs 161/1000:\n",
      "training cost 21.693699107356615|validation cost 22.502153510572793\n",
      "b: 3.4103592535185507\n",
      "epochs 162/1000:\n",
      "training cost 21.57091028947458|validation cost 22.389615145418894\n",
      "b: 3.4197918361622355\n",
      "epochs 163/1000:\n",
      "training cost 21.449607782349364|validation cost 22.278434780976248\n",
      "b: 3.4291404688203917\n",
      "epochs 164/1000:\n",
      "training cost 21.32976599534381|validation cost 22.16858854840353\n",
      "b: 3.4384058986478903\n",
      "epochs 165/1000:\n",
      "training cost 21.211359883361393|validation cost 22.06005309660411\n",
      "b: 3.447588866149924\n",
      "epochs 166/1000:\n",
      "training cost 21.094364932944796|validation cost 21.952805578925116\n",
      "b: 3.4566901052411896\n",
      "epochs 167/1000:\n",
      "training cost 20.978757148795804|validation cost 21.846823640257593\n",
      "b: 3.465710343304543\n",
      "epochs 168/1000:\n",
      "training cost 20.86451304070153|validation cost 21.7420854045238\n",
      "b: 3.4746503012491328\n",
      "epochs 169/1000:\n",
      "training cost 20.751609610852263|validation cost 21.638569462537905\n",
      "b: 3.4835106935680153\n",
      "epochs 170/1000:\n",
      "training cost 20.640024341537117|validation cost 21.53625486022715\n",
      "b: 3.49229222839526\n",
      "epochs 171/1000:\n",
      "training cost 20.529735183204146|validation cost 21.435121087200883\n",
      "b: 3.500995607562542\n",
      "epochs 172/1000:\n",
      "training cost 20.420720542872083|validation cost 21.33514806565557\n",
      "b: 3.5096215266552355\n",
      "epochs 173/1000:\n",
      "training cost 20.312959272881525|validation cost 21.23631613960415\n",
      "b: 3.5181706750680037\n",
      "epochs 174/1000:\n",
      "training cost 20.206430659973726|validation cost 21.138606064418784\n",
      "b: 3.5266437360598983\n",
      "epochs 175/1000:\n",
      "training cost 20.10111441468589|validation cost 21.041998996676295\n",
      "b: 3.5350413868089654\n",
      "epochs 176/1000:\n",
      "training cost 19.996990661051925|validation cost 20.94647648429621\n",
      "b: 3.543364298466366\n",
      "epochs 177/1000:\n",
      "training cost 19.894039926598417|validation cost 20.85202045696144\n",
      "b: 3.551613136210015\n",
      "epochs 178/1000:\n",
      "training cost 19.792243132625888|validation cost 20.758613216812325\n",
      "b: 3.5597885592977456\n",
      "epochs 179/1000:\n",
      "training cost 19.69158158476564|validation cost 20.66623742940494\n",
      "b: 3.5678912211199956\n",
      "epochs 180/1000:\n",
      "training cost 19.592036963803114|validation cost 20.574876114924894\n",
      "b: 3.5759217692520275\n",
      "epochs 181/1000:\n",
      "training cost 19.493591316758774|validation cost 20.484512639648393\n",
      "b: 3.5838808455056843\n",
      "epochs 182/1000:\n",
      "training cost 19.396227048218265|validation cost 20.395130707642306\n",
      "b: 3.5917690859806837\n",
      "epochs 183/1000:\n",
      "training cost 19.299926911903412|validation cost 20.306714352695668\n",
      "b: 3.5995871211154555\n",
      "epochs 184/1000:\n",
      "training cost 19.204674002476384|validation cost 20.219247930475042\n",
      "b: 3.607335575737528\n",
      "epochs 185/1000:\n",
      "training cost 19.110451747569385|validation cost 20.132716110896606\n",
      "b: 3.615015069113464\n",
      "epochs 186/1000:\n",
      "training cost 19.017243900032692|validation cost 20.047103870708007\n",
      "b: 3.622626214998354\n",
      "epochs 187/1000:\n",
      "training cost 18.92503453039393|validation cost 19.962396486273356\n",
      "b: 3.630169621684869\n",
      "epochs 188/1000:\n",
      "training cost 18.833808019521943|validation cost 19.878579526554944\n",
      "b: 3.6376458920518737\n",
      "epochs 189/1000:\n",
      "training cost 18.74354905148872|validation cost 19.795638846285392\n",
      "b: 3.645055623612612\n",
      "epochs 190/1000:\n",
      "training cost 18.654242606623217|validation cost 19.713560579324472\n",
      "b: 3.65239940856246\n",
      "epochs 191/1000:\n",
      "training cost 18.565873954750916|validation cost 19.632331132194608\n",
      "b: 3.659677833826254\n",
      "epochs 192/1000:\n",
      "training cost 18.47842864861349|validation cost 19.551937177789746\n",
      "b: 3.6668914811052002\n",
      "epochs 193/1000:\n",
      "training cost 18.391892517462882|validation cost 19.47236564925203\n",
      "b: 3.674040926923364\n",
      "epochs 194/1000:\n",
      "training cost 18.30625166082445|validation cost 19.39360373401134\n",
      "b: 3.681126742673746\n",
      "epochs 195/1000:\n",
      "training cost 18.221492442423976|validation cost 19.31563886798252\n",
      "b: 3.6881494946639495\n",
      "epochs 196/1000:\n",
      "training cost 18.13760148427353|validation cost 19.238458729915635\n",
      "b: 3.6951097441614404\n",
      "epochs 197/1000:\n",
      "training cost 18.054565660911447|validation cost 19.162051235894587\n",
      "b: 3.7020080474384036\n",
      "epochs 198/1000:\n",
      "training cost 17.97237209379155|validation cost 19.08640453397954\n",
      "b: 3.7088449558162018\n",
      "epochs 199/1000:\n",
      "training cost 17.891008145817395|validation cost 19.01150699898898\n",
      "b: 3.7156210157094374\n",
      "epochs 200/1000:\n",
      "training cost 17.810461416016985|validation cost 18.937347227417096\n",
      "b: 3.7223367686696234\n",
      "epochs 201/1000:\n",
      "training cost 17.730719734353848|validation cost 18.863914032482587\n",
      "b: 3.7289927514284638\n",
      "epochs 202/1000:\n",
      "training cost 17.65177115667045|validation cost 18.791196439304844\n",
      "b: 3.7355894959407503\n",
      "epochs 203/1000:\n",
      "training cost 17.573603959760042|validation cost 18.71918368020391\n",
      "b: 3.7421275294268774\n",
      "epochs 204/1000:\n",
      "training cost 17.49620663656307|validation cost 18.64786519012051\n",
      "b: 3.7486073744149784\n",
      "epochs 205/1000:\n",
      "training cost 17.41956789148464|validation cost 18.577230602152586\n",
      "b: 3.755029548782685\n",
      "epochs 206/1000:\n",
      "training cost 17.34367663582946|validation cost 18.50726974320508\n",
      "b: 3.7613945657985193\n",
      "epochs 207/1000:\n",
      "training cost 17.268521983350798|validation cost 18.437972629749513\n",
      "b: 3.7677029341629122\n",
      "epochs 208/1000:\n",
      "training cost 17.194093245910295|validation cost 18.369329463690406\n",
      "b: 3.7739551580488624\n",
      "epochs 209/1000:\n",
      "training cost 17.1203799292453|validation cost 18.30133062833517\n",
      "b: 3.7801517371422277\n",
      "epochs 210/1000:\n",
      "training cost 17.047371728840773|validation cost 18.23396668446483\n",
      "b: 3.786293166681662\n",
      "epochs 211/1000:\n",
      "training cost 16.97505852590277|validation cost 18.167228366502457\n",
      "b: 3.792379937498195\n",
      "epochs 212/1000:\n",
      "training cost 16.903430383430504|validation cost 18.101106578776694\n",
      "b: 3.798412536054461\n",
      "epochs 213/1000:\n",
      "training cost 16.83247754238439|validation cost 18.035592391877522\n",
      "b: 3.8043914444835765\n",
      "epochs 214/1000:\n",
      "training cost 16.762190417947266|validation cost 17.970677039101858\n",
      "b: 3.8103171406276726\n",
      "epochs 215/1000:\n",
      "training cost 16.692559595876165|validation cost 17.906351912986292\n",
      "b: 3.816190098076086\n",
      "epochs 216/1000:\n",
      "training cost 16.623575828942187|validation cost 17.842608561924656\n",
      "b: 3.822010786203209\n",
      "epochs 217/1000:\n",
      "training cost 16.555230033456006|validation cost 17.779438686867948\n",
      "b: 3.8277796702060005\n",
      "epochs 218/1000:\n",
      "training cost 16.48751328587662|validation cost 17.716834138104414\n",
      "b: 3.833497211141167\n",
      "epochs 219/1000:\n",
      "training cost 16.42041681950107|validation cost 17.654786912117537\n",
      "b: 3.8391638659620106\n",
      "epochs 220/1000:\n",
      "training cost 16.353932021232932|validation cost 17.593289148519784\n",
      "b: 3.8447800875549487\n",
      "epochs 221/1000:\n",
      "training cost 16.288050428427415|validation cost 17.53233312706001\n",
      "b: 3.8503463247757095\n",
      "epochs 222/1000:\n",
      "training cost 16.222763725810943|validation cost 17.47191126470259\n",
      "b: 3.8558630224852055\n",
      "epochs 223/1000:\n",
      "training cost 16.158063742473296|validation cost 17.41201611277623\n",
      "b: 3.861330621585087\n",
      "epochs 224/1000:\n",
      "training cost 16.09394244893029|validation cost 17.35264035419055\n",
      "b: 3.86674955905298\n",
      "epochs 225/1000:\n",
      "training cost 16.030391954255112|validation cost 17.293776800718803\n",
      "b: 3.8721202679774085\n",
      "epochs 226/1000:\n",
      "training cost 15.967404503276468|validation cost 17.23541839034464\n",
      "b: 3.8774431775924096\n",
      "epochs 227/1000:\n",
      "training cost 15.904972473841804|validation cost 17.17755818467148\n",
      "b: 3.8827187133118373\n",
      "epochs 228/1000:\n",
      "training cost 15.84308837414381|validation cost 17.12018936639265\n",
      "b: 3.887947296763362\n",
      "epochs 229/1000:\n",
      "training cost 15.78174484010861|validation cost 17.063305236820742\n",
      "b: 3.893129345822168\n",
      "epochs 230/1000:\n",
      "training cost 15.720934632843937|validation cost 17.006899213474544\n",
      "b: 3.8982652746443507\n",
      "epochs 231/1000:\n",
      "training cost 15.660650636145787|validation cost 16.95096482772216\n",
      "b: 3.903355493700016\n",
      "epochs 232/1000:\n",
      "training cost 15.600885854061946|validation cost 16.89549572247865\n",
      "b: 3.908400409806086\n",
      "epochs 233/1000:\n",
      "training cost 15.541633408511014|validation cost 16.840485649956946\n",
      "b: 3.9134004261588116\n",
      "epochs 234/1000:\n",
      "training cost 15.482886536955391|validation cost 16.785928469470466\n",
      "b: 3.918355942365998\n",
      "epochs 235/1000:\n",
      "training cost 15.424638590126852|validation cost 16.73181814528626\n",
      "b: 3.923267354478941\n",
      "epochs 236/1000:\n",
      "training cost 15.366883029803434|validation cost 16.67814874452722\n",
      "b: 3.9281350550240783\n",
      "epochs 237/1000:\n",
      "training cost 15.309613426636178|validation cost 16.624914435122136\n",
      "b: 3.9329594330343642\n",
      "epochs 238/1000:\n",
      "training cost 15.252823458024583|validation cost 16.572109483802446\n",
      "b: 3.9377408740803586\n",
      "epochs 239/1000:\n",
      "training cost 15.196506906039463|validation cost 16.519728254144304\n",
      "b: 3.9424797603010435\n",
      "epochs 240/1000:\n",
      "training cost 15.140657655392006|validation cost 16.467765204654977\n",
      "b: 3.947176470434364\n",
      "epochs 241/1000:\n",
      "training cost 15.085269691447886|validation cost 16.41621488690231\n",
      "b: 3.951831379847498\n",
      "epochs 242/1000:\n",
      "training cost 15.030337098285298|validation cost 16.36507194368623\n",
      "b: 3.9564448605668554\n",
      "epochs 243/1000:\n",
      "training cost 14.97585405679576|validation cost 16.314331107251217\n",
      "b: 3.9610172813078104\n",
      "epochs 244/1000:\n",
      "training cost 14.921814842826699|validation cost 16.263987197538647\n",
      "b: 3.965549007504171\n",
      "epochs 245/1000:\n",
      "training cost 14.868213825364686|validation cost 16.214035120478098\n",
      "b: 3.970040401337384\n",
      "epochs 246/1000:\n",
      "training cost 14.815045464758375|validation cost 16.16446986631652\n",
      "b: 3.974491821765481\n",
      "epochs 247/1000:\n",
      "training cost 14.762304310980138|validation cost 16.115286507984433\n",
      "b: 3.9789036245517684\n",
      "epochs 248/1000:\n",
      "training cost 14.709985001925435|validation cost 16.06648019949816\n",
      "b: 3.9832761622932575\n",
      "epochs 249/1000:\n",
      "training cost 14.658082261748996|validation cost 16.018046174397185\n",
      "b: 3.9876097844488476\n",
      "epochs 250/1000:\n",
      "training cost 14.606590899236926|validation cost 15.969979744215834\n",
      "b: 3.9919048373672528\n",
      "epochs 251/1000:\n",
      "training cost 14.55550580621381|validation cost 15.922276296988363\n",
      "b: 3.996161664314684\n",
      "epochs 252/1000:\n",
      "training cost 14.504821955984037|validation cost 15.874931295786647\n",
      "b: 4.000380605502284\n",
      "epochs 253/1000:\n",
      "training cost 14.454534401806436|validation cost 15.827940277289656\n",
      "b: 4.004561998113314\n",
      "epochs 254/1000:\n",
      "training cost 14.404638275401473|validation cost 15.781298850384035\n",
      "b: 4.008706176330105\n",
      "epochs 255/1000:\n",
      "training cost 14.355128785490196|validation cost 15.735002694794801\n",
      "b: 4.012813471360768\n",
      "epochs 256/1000:\n",
      "training cost 14.306001216364146|validation cost 15.68904755974572\n",
      "b: 4.016884211465657\n",
      "epochs 257/1000:\n",
      "training cost 14.257250926485572|validation cost 15.643429262648366\n",
      "b: 4.020918721983612\n",
      "epochs 258/1000:\n",
      "training cost 14.20887334711709|validation cost 15.598143687819364\n",
      "b: 4.024917325357959\n",
      "epochs 259/1000:\n",
      "training cost 14.160863980980242|validation cost 15.553186785225055\n",
      "b: 4.028880341162273\n",
      "epochs 260/1000:\n",
      "training cost 14.11321840094214|validation cost 15.508554569252855\n",
      "b: 4.032808086125929\n",
      "epochs 261/1000:\n",
      "training cost 14.065932248729567|validation cost 15.464243117508849\n",
      "b: 4.036700874159408\n",
      "epochs 262/1000:\n",
      "training cost 14.01900123366997|validation cost 15.420248569640815\n",
      "b: 4.040559016379389\n",
      "epochs 263/1000:\n",
      "training cost 13.972421131458544|validation cost 15.376567126186146\n",
      "b: 4.044382821133613\n",
      "epochs 264/1000:\n",
      "training cost 13.926187782950965|validation cost 15.33319504744408\n",
      "b: 4.048172594025524\n",
      "epochs 265/1000:\n",
      "training cost 13.880297092981062|validation cost 15.290128652371651\n",
      "b: 4.051928637938697\n",
      "epochs 266/1000:\n",
      "training cost 13.834745029202896|validation cost 15.24736431750279\n",
      "b: 4.0556512530610425\n",
      "epochs 267/1000:\n",
      "training cost 13.789527620956651|validation cost 15.20489847589005\n",
      "b: 4.0593407369087995\n",
      "epochs 268/1000:\n",
      "training cost 13.744640958157829|validation cost 15.162727616068402\n",
      "b: 4.062997384350311\n",
      "epochs 269/1000:\n",
      "training cost 13.700081190209108|validation cost 15.1208482810406\n",
      "b: 4.066621487629593\n",
      "epochs 270/1000:\n",
      "training cost 13.655844524934514|validation cost 15.079257067283592\n",
      "b: 4.07021333638969\n",
      "epochs 271/1000:\n",
      "training cost 13.611927227535205|validation cost 15.037950623775524\n",
      "b: 4.073773217695822\n",
      "epochs 272/1000:\n",
      "training cost 13.568325619566497|validation cost 14.996925651042796\n",
      "b: 4.077301416058329\n",
      "epochs 273/1000:\n",
      "training cost 13.5250360779356|validation cost 14.956178900226762\n",
      "b: 4.08079821345541\n",
      "epochs 274/1000:\n",
      "training cost 13.482055033919611|validation cost 14.9157071721696\n",
      "b: 4.0842638893556575\n",
      "epochs 275/1000:\n",
      "training cost 13.439378972203274|validation cost 14.87550731651889\n",
      "b: 4.087698720740392\n",
      "epochs 276/1000:\n",
      "training cost 13.39700442993609|validation cost 14.835576230850513\n",
      "b: 4.091102982125803\n",
      "epochs 277/1000:\n",
      "training cost 13.354927995808325|validation cost 14.795910859809394\n",
      "b: 4.0944769455848835\n",
      "epochs 278/1000:\n",
      "training cost 13.313146309145495|validation cost 14.756508194267738\n",
      "b: 4.097820880769178\n",
      "epochs 279/1000:\n",
      "training cost 13.271656059020899|validation cost 14.717365270500322\n",
      "b: 4.1011350549303325\n",
      "epochs 280/1000:\n",
      "training cost 13.230453983385845|validation cost 14.67847916937647\n",
      "b: 4.1044197329414525\n",
      "epochs 281/1000:\n",
      "training cost 13.189536868217075|validation cost 14.639847015568312\n",
      "b: 4.107675177318273\n",
      "epochs 282/1000:\n",
      "training cost 13.14890154668112|validation cost 14.601465976775007\n",
      "b: 4.110901648240141\n",
      "epochs 283/1000:\n",
      "training cost 13.108544898315136|validation cost 14.56333326296252\n",
      "b: 4.114099403570804\n",
      "epochs 284/1000:\n",
      "training cost 13.068463848223868|validation cost 14.525446125618611\n",
      "b: 4.117268698879023\n",
      "epochs 285/1000:\n",
      "training cost 13.028655366292423|validation cost 14.487801857022715\n",
      "b: 4.120409787459\n",
      "epochs 286/1000:\n",
      "training cost 12.989116466414417|validation cost 14.450397789530395\n",
      "b: 4.123522920350615\n",
      "epochs 287/1000:\n",
      "training cost 12.949844205735296|validation cost 14.41323129487197\n",
      "b: 4.126608346359494\n",
      "epochs 288/1000:\n",
      "training cost 12.91083568391034|validation cost 14.376299783465054\n",
      "b: 4.129666312076894\n",
      "epochs 289/1000:\n",
      "training cost 12.872088042377145|validation cost 14.339600703740766\n",
      "b: 4.13269706189941\n",
      "epochs 290/1000:\n",
      "training cost 12.833598463642238|validation cost 14.303131541483122\n",
      "b: 4.135700838048505\n",
      "epochs 291/1000:\n",
      "training cost 12.795364170581474|validation cost 14.26688981918152\n",
      "b: 4.138677880589873\n",
      "epochs 292/1000:\n",
      "training cost 12.757382425753992|validation cost 14.230873095395882\n",
      "b: 4.141628427452623\n",
      "epochs 293/1000:\n",
      "training cost 12.719650530729348|validation cost 14.195078964134295\n",
      "b: 4.144552714448295\n",
      "epochs 294/1000:\n",
      "training cost 12.682165825427633|validation cost 14.159505054242736\n",
      "b: 4.147450975289705\n",
      "epochs 295/1000:\n",
      "training cost 12.644925687472231|validation cost 14.124149028806753\n",
      "b: 4.150323441609626\n",
      "epochs 296/1000:\n",
      "training cost 12.607927531554944|validation cost 14.089008584564782\n",
      "b: 4.1531703429793\n",
      "epochs 297/1000:\n",
      "training cost 12.571168808813301|validation cost 14.054081451332808\n",
      "b: 4.1559919069267846\n",
      "epochs 298/1000:\n",
      "training cost 12.534647006219659|validation cost 14.019365391440216\n",
      "b: 4.158788358955136\n",
      "epochs 299/1000:\n",
      "training cost 12.498359645981974|validation cost 13.98485819917648\n",
      "b: 4.161559922560436\n",
      "epochs 300/1000:\n",
      "training cost 12.462304284955906|validation cost 13.95055770024858\n",
      "b: 4.1643068192496475\n",
      "epochs 301/1000:\n",
      "training cost 12.426478514068053|validation cost 13.916461751248798\n",
      "b: 4.167029268558326\n",
      "epochs 302/1000:\n",
      "training cost 12.390879957750098|validation cost 13.88256823913276\n",
      "b: 4.169727488068157\n",
      "epochs 303/1000:\n",
      "training cost 12.355506273383568|validation cost 13.848875080707417\n",
      "b: 4.172401693424351\n",
      "epochs 304/1000:\n",
      "training cost 12.320355150755077|validation cost 13.815380222128859\n",
      "b: 4.175052098352874\n",
      "epochs 305/1000:\n",
      "training cost 12.28542431152176|validation cost 13.782081638409675\n",
      "b: 4.177678914677534\n",
      "epochs 306/1000:\n",
      "training cost 12.250711508686706|validation cost 13.748977332935644\n",
      "b: 4.180282352336904\n",
      "epochs 307/1000:\n",
      "training cost 12.216214526084197|validation cost 13.716065336991644\n",
      "b: 4.182862619401106\n",
      "epochs 308/1000:\n",
      "training cost 12.181931177874532|validation cost 13.683343709296503\n",
      "b: 4.185419922088435\n",
      "epochs 309/1000:\n",
      "training cost 12.147859308048245|validation cost 13.65081053554663\n",
      "b: 4.187954464781848\n",
      "epochs 310/1000:\n",
      "training cost 12.113996789939497|validation cost 13.618463927968252\n",
      "b: 4.19046645004529\n",
      "epochs 311/1000:\n",
      "training cost 12.08034152574851|validation cost 13.586302024878064\n",
      "b: 4.192956078639886\n",
      "epochs 312/1000:\n",
      "training cost 12.046891446072785|validation cost 13.554322990252121\n",
      "b: 4.195423549539991\n",
      "epochs 313/1000:\n",
      "training cost 12.013644509446973|validation cost 13.522525013302785\n",
      "b: 4.1978690599490855\n",
      "epochs 314/1000:\n",
      "training cost 11.980598701891221|validation cost 13.490906308063598\n",
      "b: 4.200292805315539\n",
      "epochs 315/1000:\n",
      "training cost 11.947752036467762|validation cost 13.45946511298185\n",
      "b: 4.20269497934823\n",
      "epochs 316/1000:\n",
      "training cost 11.915102552845672|validation cost 13.42819969051877\n",
      "b: 4.205075774032031\n",
      "epochs 317/1000:\n",
      "training cost 11.882648316873548|validation cost 13.397108326757083\n",
      "b: 4.2074353796431465\n",
      "epochs 318/1000:\n",
      "training cost 11.850387420159983|validation cost 13.36618933101586\n",
      "b: 4.209773984764323\n",
      "epochs 319/1000:\n",
      "training cost 11.818317979661668|validation cost 13.335441035472503\n",
      "b: 4.21209177629992\n",
      "epochs 320/1000:\n",
      "training cost 11.786438137278983|validation cost 13.304861794791613\n",
      "b: 4.214388939490851\n",
      "epochs 321/1000:\n",
      "training cost 11.754746059458915|validation cost 13.274449985760826\n",
      "b: 4.216665657929382\n",
      "epochs 322/1000:\n",
      "training cost 11.72323993680513|validation cost 13.24420400693316\n",
      "b: 4.218922113573811\n",
      "epochs 323/1000:\n",
      "training cost 11.691917983695108|validation cost 13.21412227827606\n",
      "b: 4.221158486763004\n",
      "epochs 324/1000:\n",
      "training cost 11.660778437904145|validation cost 13.184203240826774\n",
      "b: 4.223374956230813\n",
      "epochs 325/1000:\n",
      "training cost 11.62981956023613|validation cost 13.154445356354037\n",
      "b: 4.225571699120359\n",
      "epochs 326/1000:\n",
      "training cost 11.59903963416094|validation cost 13.124847107025913\n",
      "b: 4.227748890998188\n",
      "epochs 327/1000:\n",
      "training cost 11.568436965458295|validation cost 13.095406995083666\n",
      "b: 4.229906705868304\n",
      "epochs 328/1000:\n",
      "training cost 11.538009881868014|validation cost 13.066123542521549\n",
      "b: 4.232045316186076\n",
      "epochs 329/1000:\n",
      "training cost 11.507756732746467|validation cost 13.036995290772358\n",
      "b: 4.23416489287202\n",
      "epochs 330/1000:\n",
      "training cost 11.477675888729152|validation cost 13.008020800398707\n",
      "b: 4.236265605325459\n",
      "epochs 331/1000:\n",
      "training cost 11.447765741399254|validation cost 12.979198650789808\n",
      "b: 4.238347621438062\n",
      "epochs 332/1000:\n",
      "training cost 11.418024702962088|validation cost 12.950527439863754\n",
      "b: 4.2404111076072635\n",
      "epochs 333/1000:\n",
      "training cost 11.388451205925259|validation cost 12.922005783775084\n",
      "b: 4.242456228749559\n",
      "epochs 334/1000:\n",
      "training cost 11.359043702784522|validation cost 12.893632316627665\n",
      "b: 4.244483148313687\n",
      "epochs 335/1000:\n",
      "training cost 11.329800665715103|validation cost 12.865405690192597\n",
      "b: 4.246492028293695\n",
      "epochs 336/1000:\n",
      "training cost 11.300720586268504|validation cost 12.83732457363125\n",
      "b: 4.248483029241881\n",
      "epochs 337/1000:\n",
      "training cost 11.27180197507458|validation cost 12.809387653223144\n",
      "b: 4.250456310281629\n",
      "epochs 338/1000:\n",
      "training cost 11.243043361548857|validation cost 12.781593632098728\n",
      "b: 4.252412029120122\n",
      "epochs 339/1000:\n",
      "training cost 11.214443293604944|validation cost 12.753941229976853\n",
      "b: 4.2543503420609525\n",
      "epochs 340/1000:\n",
      "training cost 11.186000337371965|validation cost 12.726429182906884\n",
      "b: 4.25627140401661\n",
      "epochs 341/1000:\n",
      "training cost 11.157713076916906|validation cost 12.699056243015407\n",
      "b: 4.258175368520862\n",
      "epochs 342/1000:\n",
      "training cost 11.129580113971777|validation cost 12.671821178257346\n",
      "b: 4.260062387741026\n",
      "epochs 343/1000:\n",
      "training cost 11.101600067665506|validation cost 12.644722772171498\n",
      "b: 4.261932612490131\n",
      "epochs 344/1000:\n",
      "training cost 11.073771574260473|validation cost 12.61775982364031\n",
      "b: 4.263786192238969\n",
      "epochs 345/1000:\n",
      "training cost 11.046093286893576|validation cost 12.590931146653912\n",
      "b: 4.265623275128043\n",
      "epochs 346/1000:\n",
      "training cost 11.018563875321778|validation cost 12.564235570078244\n",
      "b: 4.267444007979403\n",
      "epochs 347/1000:\n",
      "training cost 10.991182025672003|validation cost 12.537671937427245\n",
      "b: 4.269248536308386\n",
      "epochs 348/1000:\n",
      "training cost 10.963946440195366|validation cost 12.511239106638968\n",
      "b: 4.271037004335241\n",
      "epochs 349/1000:\n",
      "training cost 10.936855837025545|validation cost 12.484935949855641\n",
      "b: 4.272809554996658\n",
      "epochs 350/1000:\n",
      "training cost 10.90990894994135|validation cost 12.458761353207514\n",
      "b: 4.274566329957188\n",
      "epochs 351/1000:\n",
      "training cost 10.883104528133318|validation cost 12.432714216600433\n",
      "b: 4.276307469620569\n",
      "epochs 352/1000:\n",
      "training cost 10.85644133597425|validation cost 12.406793453507092\n",
      "b: 4.278033113140946\n",
      "epochs 353/1000:\n",
      "training cost 10.82991815279371|validation cost 12.380997990761914\n",
      "b: 4.279743398433991\n",
      "epochs 354/1000:\n",
      "training cost 10.80353377265629|validation cost 12.35532676835943\n",
      "b: 4.281438462187929\n",
      "epochs 355/1000:\n",
      "training cost 10.77728700414368|validation cost 12.329778739256097\n",
      "b: 4.283118439874457\n",
      "epochs 356/1000:\n",
      "training cost 10.751176670140367|validation cost 12.30435286917559\n",
      "b: 4.284783465759574\n",
      "epochs 357/1000:\n",
      "training cost 10.725201607623|validation cost 12.279048136417344\n",
      "b: 4.286433672914314\n",
      "epochs 358/1000:\n",
      "training cost 10.699360667453268|validation cost 12.25386353166841\n",
      "b: 4.288069193225377\n",
      "epochs 359/1000:\n",
      "training cost 10.673652714174267|validation cost 12.228798057818521\n",
      "b: 4.289690157405671\n",
      "epochs 360/1000:\n",
      "training cost 10.648076625810292|validation cost 12.203850729778257\n",
      "b: 4.29129669500476\n",
      "epochs 361/1000:\n",
      "training cost 10.622631293669961|validation cost 12.179020574300372\n",
      "b: 4.292888934419218\n",
      "epochs 362/1000:\n",
      "training cost 10.597315622152651|validation cost 12.15430662980408\n",
      "b: 4.294467002902887\n",
      "epochs 363/1000:\n",
      "training cost 10.572128528558137|validation cost 12.129707946202355\n",
      "b: 4.296031026577051\n",
      "epochs 364/1000:\n",
      "training cost 10.54706894289943|validation cost 12.105223584732117\n",
      "b: 4.297581130440515\n",
      "epochs 365/1000:\n",
      "training cost 10.522135807718698|validation cost 12.080852617787322\n",
      "b: 4.299117438379595\n",
      "epochs 366/1000:\n",
      "training cost 10.497328077906248|validation cost 12.056594128754805\n",
      "b: 4.300640073178016\n",
      "epochs 367/1000:\n",
      "training cost 10.472644720522515|validation cost 12.032447211852938\n",
      "b: 4.302149156526732\n",
      "epochs 368/1000:\n",
      "training cost 10.448084714622984|validation cost 12.008410971972939\n",
      "b: 4.303644809033644\n",
      "epochs 369/1000:\n",
      "training cost 10.423647051085995|validation cost 11.98448452452287\n",
      "b: 4.305127150233244\n",
      "epochs 370/1000:\n",
      "training cost 10.39933073244339|validation cost 11.96066699527422\n",
      "b: 4.306596298596168\n",
      "epochs 371/1000:\n",
      "training cost 10.375134772713944|validation cost 11.936957520211067\n",
      "b: 4.308052371538662\n",
      "epochs 372/1000:\n",
      "training cost 10.35105819723951|validation cost 11.913355245381727\n",
      "b: 4.309495485431968\n",
      "epochs 373/1000:\n",
      "training cost 10.327100042523892|validation cost 11.889859326752873\n",
      "b: 4.310925755611623\n",
      "epochs 374/1000:\n",
      "training cost 10.303259356074292|validation cost 11.866468930066086\n",
      "b: 4.31234329638668\n",
      "epochs 375/1000:\n",
      "training cost 10.279535196245384|validation cost 11.843183230696752\n",
      "b: 4.313748221048838\n",
      "epochs 376/1000:\n",
      "training cost 10.25592663208591|validation cost 11.820001413515337\n",
      "b: 4.315140641881504\n",
      "epochs 377/1000:\n",
      "training cost 10.23243274318779|validation cost 11.796922672750865\n",
      "b: 4.316520670168758\n",
      "epochs 378/1000:\n",
      "training cost 10.209052619537642|validation cost 11.773946211856744\n",
      "b: 4.317888416204257\n",
      "epochs 379/1000:\n",
      "training cost 10.185785361370742|validation cost 11.751071243378727\n",
      "b: 4.3192439893000385\n",
      "epochs 380/1000:\n",
      "training cost 10.162630079027341|validation cost 11.728296988825054\n",
      "b: 4.320587497795268\n",
      "epochs 381/1000:\n",
      "training cost 10.139585892811263|validation cost 11.705622678538731\n",
      "b: 4.32191904906489\n",
      "epochs 382/1000:\n",
      "training cost 10.116651932850841|validation cost 11.683047551571892\n",
      "b: 4.323238749528213\n",
      "epochs 383/1000:\n",
      "training cost 10.093827338962033|validation cost 11.660570855562183\n",
      "b: 4.324546704657411\n",
      "epochs 384/1000:\n",
      "training cost 10.071111260513769|validation cost 11.638191846611205\n",
      "b: 4.32584301898596\n",
      "epochs 385/1000:\n",
      "training cost 10.048502856295444|validation cost 11.615909789164911\n",
      "b: 4.327127796116986\n",
      "epochs 386/1000:\n",
      "training cost 10.02600129438653|validation cost 11.593723955895909\n",
      "b: 4.328401138731545\n",
      "epochs 387/1000:\n",
      "training cost 10.00360575202826|validation cost 11.571633627587739\n",
      "b: 4.329663148596834\n",
      "epochs 388/1000:\n",
      "training cost 9.98131541549739|validation cost 11.549638093020954\n",
      "b: 4.330913926574323\n",
      "epochs 389/1000:\n",
      "training cost 9.95912947998191|validation cost 11.52773664886109\n",
      "b: 4.332153572627812\n",
      "epochs 390/1000:\n",
      "training cost 9.937047149458802|validation cost 11.505928599548401\n",
      "b: 4.333382185831424\n",
      "epochs 391/1000:\n",
      "training cost 9.915067636573662|validation cost 11.484213257189406\n",
      "b: 4.334599864377525\n",
      "epochs 392/1000:\n",
      "training cost 9.893190162522286|validation cost 11.462589941450124\n",
      "b: 4.335806705584565\n",
      "epochs 393/1000:\n",
      "training cost 9.87141395693408|validation cost 11.441057979451086\n",
      "b: 4.337002805904862\n",
      "epochs 394/1000:\n",
      "training cost 9.849738257757357|validation cost 11.419616705663959\n",
      "b: 4.338188260932308\n",
      "epochs 395/1000:\n",
      "training cost 9.828162311146373|validation cost 11.398265461809872\n",
      "b: 4.339363165410011\n",
      "epochs 396/1000:\n",
      "training cost 9.80668537135021|validation cost 11.377003596759334\n",
      "b: 4.340527613237861\n",
      "epochs 397/1000:\n",
      "training cost 9.78530670060334|validation cost 11.355830466433755\n",
      "b: 4.341681697480044\n",
      "epochs 398/1000:\n",
      "training cost 9.764025569017942|validation cost 11.334745433708518\n",
      "b: 4.342825510372472\n",
      "epochs 399/1000:\n",
      "training cost 9.74284125447789|validation cost 11.313747868317613\n",
      "b: 4.3439591433301565\n",
      "epochs 400/1000:\n",
      "training cost 9.72175304253438|validation cost 11.292837146759755\n",
      "b: 4.345082686954518\n",
      "epochs 401/1000:\n",
      "training cost 9.70076022630319|validation cost 11.272012652205992\n",
      "b: 4.346196231040623\n",
      "epochs 402/1000:\n",
      "training cost 9.67986210636357|validation cost 11.251273774408777\n",
      "b: 4.347299864584362\n",
      "epochs 403/1000:\n",
      "training cost 9.659057990658633|validation cost 11.230619909612466\n",
      "b: 4.348393675789561\n",
      "epochs 404/1000:\n",
      "training cost 9.638347194397348|validation cost 11.210050460465233\n",
      "b: 4.349477752075034\n",
      "epochs 405/1000:\n",
      "training cost 9.617729039958023|validation cost 11.189564835932332\n",
      "b: 4.350552180081566\n",
      "epochs 406/1000:\n",
      "training cost 9.597202856793276|validation cost 11.169162451210767\n",
      "b: 4.35161704567884\n",
      "epochs 407/1000:\n",
      "training cost 9.576767981336477|validation cost 11.148842727645258\n",
      "b: 4.352672433972299\n",
      "epochs 408/1000:\n",
      "training cost 9.556423756909627|validation cost 11.128605092645536\n",
      "b: 4.353718429309946\n",
      "epochs 409/1000:\n",
      "training cost 9.536169533632645|validation cost 11.108448979604928\n",
      "b: 4.354755115289087\n",
      "epochs 410/1000:\n",
      "training cost 9.516004668334059|validation cost 11.088373827820181\n",
      "b: 4.355782574763014\n",
      "epochs 411/1000:\n",
      "training cost 9.495928524463043|validation cost 11.068379082412585\n",
      "b: 4.356800889847623\n",
      "epochs 412/1000:\n",
      "training cost 9.475940472002817|validation cost 11.04846419425025\n",
      "b: 4.357810141927979\n",
      "epochs 413/1000:\n",
      "training cost 9.456039887385343|validation cost 11.028628619871652\n",
      "b: 4.3588104116648205\n",
      "epochs 414/1000:\n",
      "training cost 9.436226153407361|validation cost 11.0088718214103\n",
      "b: 4.359801779001003\n",
      "epochs 415/1000:\n",
      "training cost 9.416498659147637|validation cost 10.989193266520623\n",
      "b: 4.360784323167894\n",
      "epochs 416/1000:\n",
      "training cost 9.39685679988553|validation cost 10.969592428304939\n",
      "b: 4.3617581226916995\n",
      "epochs 417/1000:\n",
      "training cost 9.377299977020742|validation cost 10.95006878524159\n",
      "b: 4.362723255399743\n",
      "epochs 418/1000:\n",
      "training cost 9.357827597994326|validation cost 10.930621821114169\n",
      "b: 4.363679798426685\n",
      "epochs 419/1000:\n",
      "training cost 9.33843907621083|validation cost 10.911251024941809\n",
      "b: 4.364627828220687\n",
      "epochs 420/1000:\n",
      "training cost 9.319133830961666|validation cost 10.891955890910564\n",
      "b: 4.365567420549523\n",
      "epochs 421/1000:\n",
      "training cost 9.299911287349595|validation cost 10.872735918305835\n",
      "b: 4.366498650506632\n",
      "epochs 422/1000:\n",
      "training cost 9.280770876214362|validation cost 10.853590611445805\n",
      "b: 4.367421592517123\n",
      "epochs 423/1000:\n",
      "training cost 9.261712034059444|validation cost 10.834519479615905\n",
      "b: 4.368336320343721\n",
      "epochs 424/1000:\n",
      "training cost 9.242734202979882|validation cost 10.815522037004259\n",
      "b: 4.369242907092661\n",
      "epochs 425/1000:\n",
      "training cost 9.223836830591202|validation cost 10.796597802638138\n",
      "b: 4.370141425219536\n",
      "epochs 426/1000:\n",
      "training cost 9.205019369959382|validation cost 10.777746300321336\n",
      "b: 4.371031946535083\n",
      "epochs 427/1000:\n",
      "training cost 9.186281279531885|validation cost 10.758967058572516\n",
      "b: 4.37191454221092\n",
      "epochs 428/1000:\n",
      "training cost 9.167622023069672|validation cost 10.74025961056448\n",
      "b: 4.372789282785243\n",
      "epochs 429/1000:\n",
      "training cost 9.14904106958028|validation cost 10.721623494064348\n",
      "b: 4.373656238168454\n",
      "epochs 430/1000:\n",
      "training cost 9.130537893251832|validation cost 10.703058251374664\n",
      "b: 4.374515477648755\n",
      "epochs 431/1000:\n",
      "training cost 9.112111973388071|validation cost 10.684563429275322\n",
      "b: 4.375367069897681\n",
      "epochs 432/1000:\n",
      "training cost 9.093762794344302|validation cost 10.666138578966436\n",
      "b: 4.376211082975592\n",
      "epochs 433/1000:\n",
      "training cost 9.07548984546433|validation cost 10.647783256012012\n",
      "b: 4.3770475843371095\n",
      "epochs 434/1000:\n",
      "training cost 9.057292621018286|validation cost 10.629497020284491\n",
      "b: 4.377876640836509\n",
      "epochs 435/1000:\n",
      "training cost 9.039170620141372|validation cost 10.611279435910086\n",
      "b: 4.378698318733064\n",
      "epochs 436/1000:\n",
      "training cost 9.021123346773507|validation cost 10.593130071214985\n",
      "b: 4.37951268369634\n",
      "epochs 437/1000:\n",
      "training cost 9.003150309599869|validation cost 10.57504849867227\n",
      "b: 4.380319800811442\n",
      "epochs 438/1000:\n",
      "training cost 8.985251021992267|validation cost 10.557034294849721\n",
      "b: 4.38111973458422\n",
      "epochs 439/1000:\n",
      "training cost 8.967425001951403|validation cost 10.539087040358313\n",
      "b: 4.381912548946421\n",
      "epochs 440/1000:\n",
      "training cost 8.949671772049957|validation cost 10.521206319801516\n",
      "b: 4.382698307260798\n",
      "epochs 441/1000:\n",
      "training cost 8.931990859376494|validation cost 10.503391721725325\n",
      "b: 4.383477072326176\n",
      "epochs 442/1000:\n",
      "training cost 8.914381795480196|validation cost 10.485642838569033\n",
      "b: 4.384248906382473\n",
      "epochs 443/1000:\n",
      "training cost 8.896844116316379|validation cost 10.46795926661673\n",
      "b: 4.385013871115669\n",
      "epochs 444/1000:\n",
      "training cost 8.879377362192807|validation cost 10.450340605949494\n",
      "b: 4.38577202766274\n",
      "epochs 445/1000:\n",
      "training cost 8.86198107771677|validation cost 10.43278646039832\n",
      "b: 4.3865234366165415\n",
      "epochs 446/1000:\n",
      "training cost 8.84465481174294|validation cost 10.415296437497693\n",
      "b: 4.387268158030654\n",
      "epochs 447/1000:\n",
      "training cost 8.827398117321948|validation cost 10.397870148439875\n",
      "b: 4.388006251424181\n",
      "epochs 448/1000:\n",
      "training cost 8.810210551649718|validation cost 10.380507208029828\n",
      "b: 4.388737775786506\n",
      "epochs 449/1000:\n",
      "training cost 8.793091676017529|validation cost 10.363207234640818\n",
      "b: 4.389462789582006\n",
      "epochs 450/1000:\n",
      "training cost 8.776041055762775|validation cost 10.34596985017066\n",
      "b: 4.390181350754726\n",
      "epochs 451/1000:\n",
      "training cost 8.759058260220428|validation cost 10.328794679998563\n",
      "b: 4.3908935167330085\n",
      "epochs 452/1000:\n",
      "training cost 8.742142862675207|validation cost 10.311681352942664\n",
      "b: 4.391599344434085\n",
      "epochs 453/1000:\n",
      "training cost 8.725294440314416|validation cost 10.294629501218102\n",
      "b: 4.392298890268622\n",
      "epochs 454/1000:\n",
      "training cost 8.708512574181439|validation cost 10.277638760395757\n",
      "b: 4.3929922101452314\n",
      "epochs 455/1000:\n",
      "training cost 8.691796849129918|validation cost 10.26070876936155\n",
      "b: 4.393679359474939\n",
      "epochs 456/1000:\n",
      "training cost 8.675146853778559|validation cost 10.243839170276338\n",
      "b: 4.394360393175612\n",
      "epochs 457/1000:\n",
      "training cost 8.658562180466584|validation cost 10.22702960853638\n",
      "b: 4.395035365676349\n",
      "epochs 458/1000:\n",
      "training cost 8.642042425209802|validation cost 10.210279732734381\n",
      "b: 4.395704330921829\n",
      "epochs 459/1000:\n",
      "training cost 8.625587187657304|validation cost 10.193589194621067\n",
      "b: 4.3963673423766245\n",
      "epochs 460/1000:\n",
      "training cost 8.609196071048775|validation cost 10.176957649067347\n",
      "b: 4.397024453029473\n",
      "epochs 461/1000:\n",
      "training cost 8.592868682172375|validation cost 10.16038475402697\n",
      "b: 4.397675715397511\n",
      "epochs 462/1000:\n",
      "training cost 8.57660463132324|validation cost 10.143870170499756\n",
      "b: 4.398321181530473\n",
      "epochs 463/1000:\n",
      "training cost 8.560403532262539|validation cost 10.12741356249532\n",
      "b: 4.398960903014851\n",
      "epochs 464/1000:\n",
      "training cost 8.544265002177118|validation cost 10.11101459699732\n",
      "b: 4.399594930978019\n",
      "epochs 465/1000:\n",
      "training cost 8.528188661639687|validation cost 10.094672943928199\n",
      "b: 4.4002233160923145\n",
      "epochs 466/1000:\n",
      "training cost 8.51217413456958|validation cost 10.078388276114461\n",
      "b: 4.400846108579093\n",
      "epochs 467/1000:\n",
      "training cost 8.496221048194045|validation cost 10.06216026925239\n",
      "b: 4.401463358212739\n",
      "epochs 468/1000:\n",
      "training cost 8.48032903301006|validation cost 10.045988601874267\n",
      "b: 4.402075114324646\n",
      "epochs 469/1000:\n",
      "training cost 8.464497722746714|validation cost 10.029872955315112\n",
      "b: 4.402681425807156\n",
      "epochs 470/1000:\n",
      "training cost 8.448726754328053|validation cost 10.013813013679789\n",
      "b: 4.403282341117472\n",
      "epochs 471/1000:\n",
      "training cost 8.433015767836483|validation cost 9.997808463810674\n",
      "b: 4.403877908281526\n",
      "epochs 472/1000:\n",
      "training cost 8.417364406476647|validation cost 9.981858995255708\n",
      "b: 4.40446817489782\n",
      "epochs 473/1000:\n",
      "training cost 8.40177231653981|validation cost 9.965964300236939\n",
      "b: 4.405053188141229\n",
      "epochs 474/1000:\n",
      "training cost 8.386239147368725|validation cost 9.950124073619468\n",
      "b: 4.405632994766773\n",
      "epochs 475/1000:\n",
      "training cost 8.37076455132299|validation cost 9.934338012880852\n",
      "b: 4.406207641113348\n",
      "epochs 476/1000:\n",
      "training cost 8.355348183744853|validation cost 9.918605818080916\n",
      "b: 4.406777173107439\n",
      "epochs 477/1000:\n",
      "training cost 8.339989702925514|validation cost 9.902927191831985\n",
      "b: 4.407341636266783\n",
      "epochs 478/1000:\n",
      "training cost 8.324688770071855|validation cost 9.887301839269549\n",
      "b: 4.407901075704008\n",
      "epochs 479/1000:\n",
      "training cost 8.309445049273643|validation cost 9.871729468023299\n",
      "b: 4.408455536130242\n",
      "epochs 480/1000:\n",
      "training cost 8.294258207471161|validation cost 9.856209788188588\n",
      "b: 4.409005061858683\n",
      "epochs 481/1000:\n",
      "training cost 8.27912791442329|validation cost 9.840742512298274\n",
      "b: 4.409549696808141\n",
      "epochs 482/1000:\n",
      "training cost 8.264053842676008|validation cost 9.825327355294943\n",
      "b: 4.410089484506549\n",
      "epochs 483/1000:\n",
      "training cost 8.249035667531318|validation cost 9.809964034503547\n",
      "b: 4.410624468094441\n",
      "epochs 484/1000:\n",
      "training cost 8.234073067016604|validation cost 9.794652269604368\n",
      "b: 4.4111546903284005\n",
      "epochs 485/1000:\n",
      "training cost 8.21916572185438|validation cost 9.779391782606384\n",
      "b: 4.411680193584478\n",
      "epochs 486/1000:\n",
      "training cost 8.20431331543245|validation cost 9.764182297820982\n",
      "b: 4.412201019861576\n",
      "epochs 487/1000:\n",
      "training cost 8.189515533774477|validation cost 9.749023541836054\n",
      "b: 4.412717210784808\n",
      "epochs 488/1000:\n",
      "training cost 8.17477206551093|validation cost 9.73391524349041\n",
      "b: 4.4132288076088235\n",
      "epochs 489/1000:\n",
      "training cost 8.160082601850426|validation cost 9.718857133848566\n",
      "b: 4.413735851221105\n",
      "epochs 490/1000:\n",
      "training cost 8.145446836551448|validation cost 9.703848946175857\n",
      "b: 4.414238382145237\n",
      "epochs 491/1000:\n",
      "training cost 8.130864465894442|validation cost 9.68889041591389\n",
      "b: 4.414736440544145\n",
      "epochs 492/1000:\n",
      "training cost 8.116335188654286|validation cost 9.673981280656356\n",
      "b: 4.415230066223302\n",
      "epochs 493/1000:\n",
      "training cost 8.101858706073111|validation cost 9.65912128012511\n",
      "b: 4.415719298633914\n",
      "epochs 494/1000:\n",
      "training cost 8.087434721833493|validation cost 9.644310156146615\n",
      "b: 4.4162041768760725\n",
      "epochs 495/1000:\n",
      "training cost 8.07306294203199|validation cost 9.629547652628714\n",
      "b: 4.416684739701876\n",
      "epochs 496/1000:\n",
      "training cost 8.058743075153034|validation cost 9.614833515537672\n",
      "b: 4.417161025518529\n",
      "epochs 497/1000:\n",
      "training cost 8.044474832043157|validation cost 9.600167492875547\n",
      "b: 4.417633072391414\n",
      "epochs 498/1000:\n",
      "training cost 8.030257925885557|validation cost 9.585549334657872\n",
      "b: 4.418100918047131\n",
      "epochs 499/1000:\n",
      "training cost 8.016092072175008|validation cost 9.570978792891612\n",
      "b: 4.418564599876511\n",
      "epochs 500/1000:\n",
      "training cost 8.001976988693071|validation cost 9.55645562155345\n",
      "b: 4.41902415493761\n",
      "epochs 501/1000:\n",
      "training cost 7.9879123954836615|validation cost 9.541979576568304\n",
      "b: 4.419479619958665\n",
      "epochs 502/1000:\n",
      "training cost 7.9738980148288965|validation cost 9.527550415788193\n",
      "b: 4.419931031341033\n",
      "epochs 503/1000:\n",
      "training cost 7.9599335712252985|validation cost 9.513167898971341\n",
      "b: 4.420378425162098\n",
      "epochs 504/1000:\n",
      "training cost 7.946018791360264|validation cost 9.498831787761569\n",
      "b: 4.420821837178155\n",
      "epochs 505/1000:\n",
      "training cost 7.932153404088868|validation cost 9.48454184566796\n",
      "b: 4.421261302827269\n",
      "epochs 506/1000:\n",
      "training cost 7.91833714041095|validation cost 9.4702978380448\n",
      "b: 4.4216968572321065\n",
      "epochs 507/1000:\n",
      "training cost 7.9045697334485014|validation cost 9.456099532071756\n",
      "b: 4.422128535202741\n",
      "epochs 508/1000:\n",
      "training cost 7.890850918423357|validation cost 9.441946696734345\n",
      "b: 4.422556371239437\n",
      "epochs 509/1000:\n",
      "training cost 7.877180432635131|validation cost 9.427839102804636\n",
      "b: 4.422980399535406\n",
      "epochs 510/1000:\n",
      "training cost 7.863558015439488|validation cost 9.41377652282223\n",
      "b: 4.423400653979541\n",
      "epochs 511/1000:\n",
      "training cost 7.8499834082266595|validation cost 9.399758731075458\n",
      "b: 4.423817168159123\n",
      "epochs 512/1000:\n",
      "training cost 7.836456354400236|validation cost 9.385785503582834\n",
      "b: 4.424229975362507\n",
      "epochs 513/1000:\n",
      "training cost 7.82297659935624|validation cost 9.371856618074762\n",
      "b: 4.42463910858178\n",
      "epochs 514/1000:\n",
      "training cost 7.809543890462461|validation cost 9.357971853975474\n",
      "b: 4.4250446005154025\n",
      "epochs 515/1000:\n",
      "training cost 7.7961579770380505|validation cost 9.344130992385194\n",
      "b: 4.425446483570815\n",
      "epochs 516/1000:\n",
      "training cost 7.782818610333378|validation cost 9.330333816062534\n",
      "b: 4.4258447898670354\n",
      "epochs 517/1000:\n",
      "training cost 7.7695255435101345|validation cost 9.31658010940713\n",
      "b: 4.426239551237219\n",
      "epochs 518/1000:\n",
      "training cost 7.756278531621693|validation cost 9.302869658442486\n",
      "b: 4.426630799231208\n",
      "epochs 519/1000:\n",
      "training cost 7.743077331593729|validation cost 9.28920225079905\n",
      "b: 4.42701856511805\n",
      "epochs 520/1000:\n",
      "training cost 7.729921702205052|validation cost 9.275577675697502\n",
      "b: 4.427402879888499\n",
      "epochs 521/1000:\n",
      "training cost 7.71681140406871|validation cost 9.261995723932252\n",
      "b: 4.427783774257491\n",
      "epochs 522/1000:\n",
      "training cost 7.70374619961331|validation cost 9.248456187855169\n",
      "b: 4.428161278666599\n",
      "epochs 523/1000:\n",
      "training cost 7.690725853064587|validation cost 9.23495886135948\n",
      "b: 4.428535423286466\n",
      "epochs 524/1000:\n",
      "training cost 7.677750130427184|validation cost 9.22150353986392\n",
      "b: 4.428906238019217\n",
      "epochs 525/1000:\n",
      "training cost 7.664818799466681|validation cost 9.208090020297039\n",
      "b: 4.429273752500846\n",
      "epochs 526/1000:\n",
      "training cost 7.651931629691826|validation cost 9.194718101081754\n",
      "b: 4.4296379961035885\n",
      "epochs 527/1000:\n",
      "training cost 7.639088392337007|validation cost 9.18138758212005\n",
      "b: 4.429998997938267\n",
      "epochs 528/1000:\n",
      "training cost 7.626288860344924|validation cost 9.168098264777916\n",
      "b: 4.430356786856616\n",
      "epochs 529/1000:\n",
      "training cost 7.6135328083494755|validation cost 9.154849951870432\n",
      "b: 4.430711391453592\n",
      "epochs 530/1000:\n",
      "training cost 7.600820012658875|validation cost 9.141642447647092\n",
      "b: 4.431062840069655\n",
      "epochs 531/1000:\n",
      "training cost 7.588150251238958|validation cost 9.12847555777725\n",
      "b: 4.431411160793035\n",
      "epochs 532/1000:\n",
      "training cost 7.575523303696691|validation cost 9.115349089335819\n",
      "b: 4.431756381461977\n",
      "epochs 533/1000:\n",
      "training cost 7.562938951263899|validation cost 9.102262850789087\n",
      "b: 4.432098529666965\n",
      "epochs 534/1000:\n",
      "training cost 7.550396976781179|validation cost 9.08921665198074\n",
      "b: 4.432437632752929\n",
      "epochs 535/1000:\n",
      "training cost 7.537897164682014|validation cost 9.07621030411808\n",
      "b: 4.432773717821428\n",
      "epochs 536/1000:\n",
      "training cost 7.525439300977083|validation cost 9.063243619758348\n",
      "b: 4.433106811732817\n",
      "epochs 537/1000:\n",
      "training cost 7.513023173238758|validation cost 9.050316412795304\n",
      "b: 4.433436941108395\n",
      "epochs 538/1000:\n",
      "training cost 7.500648570585793|validation cost 9.037428498445903\n",
      "b: 4.433764132332531\n",
      "epochs 539/1000:\n",
      "training cost 7.488315283668191|validation cost 9.024579693237168\n",
      "b: 4.434088411554772\n",
      "epochs 540/1000:\n",
      "training cost 7.4760231046522705|validation cost 9.011769814993226\n",
      "b: 4.434409804691934\n",
      "epochs 541/1000:\n",
      "training cost 7.4637718272058935|validation cost 8.998998682822501\n",
      "b: 4.434728337430176\n",
      "epochs 542/1000:\n",
      "training cost 7.451561246483875|validation cost 8.986266117105043\n",
      "b: 4.4350440352270475\n",
      "epochs 543/1000:\n",
      "training cost 7.439391159113584|validation cost 8.973571939480056\n",
      "b: 4.435356923313527\n",
      "epochs 544/1000:\n",
      "training cost 7.427261363180699|validation cost 8.960915972833543\n",
      "b: 4.435667026696036\n",
      "epochs 545/1000:\n",
      "training cost 7.415171658215147|validation cost 8.948298041286114\n",
      "b: 4.4359743701584415\n",
      "epochs 546/1000:\n",
      "training cost 7.403121845177194|validation cost 8.935717970180951\n",
      "b: 4.436278978264031\n",
      "epochs 547/1000:\n",
      "training cost 7.391111726443722|validation cost 8.923175586071906\n",
      "b: 4.436580875357482\n",
      "epochs 548/1000:\n",
      "training cost 7.379141105794656|validation cost 8.910670716711754\n",
      "b: 4.4368800855668\n",
      "epochs 549/1000:\n",
      "training cost 7.36720978839956|validation cost 8.898203191040588\n",
      "b: 4.437176632805255\n",
      "epochs 550/1000:\n",
      "training cost 7.355317580804381|validation cost 8.885772839174349\n",
      "b: 4.437470540773289\n",
      "epochs 551/1000:\n",
      "training cost 7.343464290918365|validation cost 8.87337949239349\n",
      "b: 4.4377618329604065\n",
      "epochs 552/1000:\n",
      "training cost 7.331649728001113|validation cost 8.861022983131818\n",
      "b: 4.4380505326470585\n",
      "epochs 553/1000:\n",
      "training cost 7.319873702649807|validation cost 8.848703144965397\n",
      "b: 4.4383366629065\n",
      "epochs 554/1000:\n",
      "training cost 7.308136026786559|validation cost 8.836419812601648\n",
      "b: 4.438620246606632\n",
      "epochs 555/1000:\n",
      "training cost 7.296436513645946|validation cost 8.824172821868567\n",
      "b: 4.438901306411833\n",
      "epochs 556/1000:\n",
      "training cost 7.284774977762657|validation cost 8.811962009704043\n",
      "b: 4.439179864784768\n",
      "epochs 557/1000:\n",
      "training cost 7.273151234959305|validation cost 8.799787214145335\n",
      "b: 4.439455943988183\n",
      "epochs 558/1000:\n",
      "training cost 7.261565102334373|validation cost 8.787648274318665\n",
      "b: 4.4397295660866885\n",
      "epochs 559/1000:\n",
      "training cost 7.250016398250301|validation cost 8.77554503042894\n",
      "b: 4.440000752948517\n",
      "epochs 560/1000:\n",
      "training cost 7.2385049423217165|validation cost 8.763477323749576\n",
      "b: 4.440269526247276\n",
      "epochs 561/1000:\n",
      "training cost 7.2270305554038|validation cost 8.751444996612468\n",
      "b: 4.440535907463675\n",
      "epochs 562/1000:\n",
      "training cost 7.215593059580782|validation cost 8.739447892398074\n",
      "b: 4.440799917887249\n",
      "epochs 563/1000:\n",
      "training cost 7.20419227815457|validation cost 8.727485855525604\n",
      "b: 4.4410615786180525\n",
      "epochs 564/1000:\n",
      "training cost 7.192828035633521|validation cost 8.71555873144333\n",
      "b: 4.4413209105683515\n",
      "epochs 565/1000:\n",
      "training cost 7.181500157721329|validation cost 8.703666366619021\n",
      "b: 4.441577934464293\n",
      "epochs 566/1000:\n",
      "training cost 7.170208471306047|validation cost 8.691808608530483\n",
      "b: 4.441832670847561\n",
      "epochs 567/1000:\n",
      "training cost 7.158952804449236|validation cost 8.679985305656194\n",
      "b: 4.442085140077018\n",
      "epochs 568/1000:\n",
      "training cost 7.14773298637523|validation cost 8.668196307466086\n",
      "b: 4.442335362330333\n",
      "epochs 569/1000:\n",
      "training cost 7.13654884746054|validation cost 8.656441464412403\n",
      "b: 4.442583357605593\n",
      "epochs 570/1000:\n",
      "training cost 7.125400219223359|validation cost 8.64472062792067\n",
      "b: 4.442829145722904\n",
      "epochs 571/1000:\n",
      "training cost 7.1142869343132|validation cost 8.633033650380785\n",
      "b: 4.44307274632597\n",
      "epochs 572/1000:\n",
      "training cost 7.103208826500653|validation cost 8.621380385138199\n",
      "b: 4.443314178883669\n",
      "epochs 573/1000:\n",
      "training cost 7.092165730667247|validation cost 8.609760686485206\n",
      "b: 4.443553462691604\n",
      "epochs 574/1000:\n",
      "training cost 7.081157482795437|validation cost 8.598174409652314\n",
      "b: 4.443790616873649\n",
      "epochs 575/1000:\n",
      "training cost 7.070183919958696|validation cost 8.586621410799763\n",
      "b: 4.444025660383473\n",
      "epochs 576/1000:\n",
      "training cost 7.059244880311736|validation cost 8.575101547009076\n",
      "b: 4.4442586120060605\n",
      "epochs 577/1000:\n",
      "training cost 7.048340203080809|validation cost 8.56361467627477\n",
      "b: 4.4444894903592065\n",
      "epochs 578/1000:\n",
      "training cost 7.037469728554146|validation cost 8.552160657496122\n",
      "b: 4.4447183138950095\n",
      "epochs 579/1000:\n",
      "training cost 7.026633298072489|validation cost 8.540739350469032\n",
      "b: 4.444945100901344\n",
      "epochs 580/1000:\n",
      "training cost 7.01583075401973|validation cost 8.529350615878014\n",
      "b: 4.445169869503322\n",
      "epochs 581/1000:\n",
      "training cost 7.005061939813661|validation cost 8.517994315288227\n",
      "b: 4.445392637664742\n",
      "epochs 582/1000:\n",
      "training cost 6.994326699896818|validation cost 8.506670311137645\n",
      "b: 4.445613423189526\n",
      "epochs 583/1000:\n",
      "training cost 6.983624879727431|validation cost 8.495378466729276\n",
      "b: 4.445832243723139\n",
      "epochs 584/1000:\n",
      "training cost 6.972956325770478|validation cost 8.4841186462235\n",
      "b: 4.446049116754003\n",
      "epochs 585/1000:\n",
      "training cost 6.962320885488831|validation cost 8.47289071463048\n",
      "b: 4.446264059614893\n",
      "epochs 586/1000:\n",
      "training cost 6.951718407334509|validation cost 8.461694537802666\n",
      "b: 4.44647708948432\n",
      "epochs 587/1000:\n",
      "training cost 6.941148740740019|validation cost 8.45052998242736\n",
      "b: 4.44668822338791\n",
      "epochs 588/1000:\n",
      "training cost 6.930611736109793|validation cost 8.439396916019405\n",
      "b: 4.446897478199758\n",
      "epochs 589/1000:\n",
      "training cost 6.920107244811734|validation cost 8.428295206913914\n",
      "b: 4.44710487064378\n",
      "epochs 590/1000:\n",
      "training cost 6.909635119168826|validation cost 8.417224724259132\n",
      "b: 4.44731041729505\n",
      "epochs 591/1000:\n",
      "training cost 6.8991952124508655|validation cost 8.40618533800931\n",
      "b: 4.447514134581124\n",
      "epochs 592/1000:\n",
      "training cost 6.8887873788662635|validation cost 8.395176918917723\n",
      "b: 4.447716038783352\n",
      "epochs 593/1000:\n",
      "training cost 6.878411473553951|validation cost 8.384199338529731\n",
      "b: 4.447916146038181\n",
      "epochs 594/1000:\n",
      "training cost 6.868067352575358|validation cost 8.373252469175922\n",
      "b: 4.448114472338441\n",
      "epochs 595/1000:\n",
      "training cost 6.857754872906494|validation cost 8.362336183965338\n",
      "b: 4.448311033534629\n",
      "epochs 596/1000:\n",
      "training cost 6.847473892430101|validation cost 8.351450356778773\n",
      "b: 4.448505845336171\n",
      "epochs 597/1000:\n",
      "training cost 6.837224269927906|validation cost 8.340594862262146\n",
      "b: 4.448698923312679\n",
      "epochs 598/1000:\n",
      "training cost 6.827005865072941|validation cost 8.329769575819942\n",
      "b: 4.448890282895197\n",
      "epochs 599/1000:\n",
      "training cost 6.81681853842196|validation cost 8.31897437360873\n",
      "b: 4.449079939377429\n",
      "epochs 600/1000:\n",
      "training cost 6.8066621514079335|validation cost 8.308209132530761\n",
      "b: 4.44926790791697\n",
      "epochs 601/1000:\n",
      "training cost 6.796536566332614|validation cost 8.297473730227622\n",
      "b: 4.449454203536509\n",
      "epochs 602/1000:\n",
      "training cost 6.786441646359195|validation cost 8.286768045073954\n",
      "b: 4.449638841125034\n",
      "epochs 603/1000:\n",
      "training cost 6.776377255505041|validation cost 8.276091956171268\n",
      "b: 4.449821835439021\n",
      "epochs 604/1000:\n",
      "training cost 6.766343258634501|validation cost 8.265445343341796\n",
      "b: 4.4500032011036135\n",
      "epochs 605/1000:\n",
      "training cost 6.756339521451781|validation cost 8.254828087122435\n",
      "b: 4.450182952613791\n",
      "epochs 606/1000:\n",
      "training cost 6.74636591049392|validation cost 8.244240068758739\n",
      "b: 4.450361104335529\n",
      "epochs 607/1000:\n",
      "training cost 6.736422293123824|validation cost 8.233681170198976\n",
      "b: 4.450537670506942\n",
      "epochs 608/1000:\n",
      "training cost 6.726508537523363|validation cost 8.223151274088265\n",
      "b: 4.45071266523943\n",
      "epochs 609/1000:\n",
      "training cost 6.716624512686572|validation cost 8.212650263762768\n",
      "b: 4.450886102518799\n",
      "epochs 610/1000:\n",
      "training cost 6.706770088412891|validation cost 8.202178023243938\n",
      "b: 4.451057996206382\n",
      "epochs 611/1000:\n",
      "training cost 6.6969451353004965|validation cost 8.191734437232837\n",
      "b: 4.451228360040145\n",
      "epochs 612/1000:\n",
      "training cost 6.6871495247396995|validation cost 8.181319391104513\n",
      "b: 4.451397207635788\n",
      "epochs 613/1000:\n",
      "training cost 6.677383128906405|validation cost 8.170932770902432\n",
      "b: 4.451564552487829\n",
      "epochs 614/1000:\n",
      "training cost 6.66764582075565|validation cost 8.16057446333299\n",
      "b: 4.451730407970688\n",
      "epochs 615/1000:\n",
      "training cost 6.657937474015198|validation cost 8.150244355760048\n",
      "b: 4.451894787339749\n",
      "epochs 616/1000:\n",
      "training cost 6.648257963179218|validation cost 8.139942336199562\n",
      "b: 4.452057703732425\n",
      "epochs 617/1000:\n",
      "training cost 6.638607163502005|validation cost 8.129668293314245\n",
      "b: 4.452219170169206\n",
      "epochs 618/1000:\n",
      "training cost 6.628984950991784|validation cost 8.119422116408288\n",
      "b: 4.4523791995547\n",
      "epochs 619/1000:\n",
      "training cost 6.619391202404574|validation cost 8.109203695422163\n",
      "b: 4.452537804678664\n",
      "epochs 620/1000:\n",
      "training cost 6.609825795238119|validation cost 8.099012920927443\n",
      "b: 4.452694998217024\n",
      "epochs 621/1000:\n",
      "training cost 6.60028860772586|validation cost 8.088849684121707\n",
      "b: 4.452850792732892\n",
      "epochs 622/1000:\n",
      "training cost 6.590779518831002|validation cost 8.078713876823471\n",
      "b: 4.45300520067757\n",
      "epochs 623/1000:\n",
      "training cost 6.581298408240623|validation cost 8.068605391467209\n",
      "b: 4.453158234391539\n",
      "epochs 624/1000:\n",
      "training cost 6.57184515635984|validation cost 8.058524121098383\n",
      "b: 4.453309906105455\n",
      "epochs 625/1000:\n",
      "training cost 6.562419644306044|validation cost 8.048469959368564\n",
      "b: 4.453460227941116\n",
      "epochs 626/1000:\n",
      "training cost 6.553021753903195|validation cost 8.038442800530579\n",
      "b: 4.453609211912441\n",
      "epochs 627/1000:\n",
      "training cost 6.5436513676761665|validation cost 8.028442539433716\n",
      "b: 4.45375686992642\n",
      "epochs 628/1000:\n",
      "training cost 6.534308368845152|validation cost 8.018469071518979\n",
      "b: 4.453903213784075\n",
      "epochs 629/1000:\n",
      "training cost 6.524992641320129|validation cost 8.0085222928144\n",
      "b: 4.454048255181397\n",
      "epochs 630/1000:\n",
      "training cost 6.5157040696953805|validation cost 7.998602099930378\n",
      "b: 4.454192005710283\n",
      "epochs 631/1000:\n",
      "training cost 6.506442539244068|validation cost 7.988708390055092\n",
      "b: 4.4543344768594615\n",
      "epochs 632/1000:\n",
      "training cost 6.497207935912863|validation cost 7.978841060949957\n",
      "b: 4.454475680015412\n",
      "epochs 633/1000:\n",
      "training cost 6.488000146316628|validation cost 7.969000010945083\n",
      "b: 4.4546156264632755\n",
      "epochs 634/1000:\n",
      "training cost 6.478819057733154|validation cost 7.959185138934871\n",
      "b: 4.454754327387752\n",
      "epochs 635/1000:\n",
      "training cost 6.469664558097955|validation cost 7.949396344373555\n",
      "b: 4.454891793874001\n",
      "epochs 636/1000:\n",
      "training cost 6.460536535999106|validation cost 7.939633527270849\n",
      "b: 4.455028036908523\n",
      "epochs 637/1000:\n",
      "training cost 6.451434880672137|validation cost 7.92989658818763\n",
      "b: 4.455163067380037\n",
      "epochs 638/1000:\n",
      "training cost 6.442359481994977|validation cost 7.9201854282316635\n",
      "b: 4.455296896080355\n",
      "epochs 639/1000:\n",
      "training cost 6.433310230482952|validation cost 7.910499949053347\n",
      "b: 4.4554295337052405\n",
      "epochs 640/1000:\n",
      "training cost 6.424287017283834|validation cost 7.900840052841534\n",
      "b: 4.455560990855264\n",
      "epochs 641/1000:\n",
      "training cost 6.415289734172918|validation cost 7.891205642319384\n",
      "b: 4.455691278036652\n",
      "epochs 642/1000:\n",
      "training cost 6.406318273548186|validation cost 7.881596620740244\n",
      "b: 4.455820405662126\n",
      "epochs 643/1000:\n",
      "training cost 6.397372528425481|validation cost 7.872012891883595\n",
      "b: 4.455948384051733\n",
      "epochs 644/1000:\n",
      "training cost 6.388452392433754|validation cost 7.862454360051014\n",
      "b: 4.456075223433673\n",
      "epochs 645/1000:\n",
      "training cost 6.379557759810343|validation cost 7.852920930062206\n",
      "b: 4.456200933945113\n",
      "epochs 646/1000:\n",
      "training cost 6.370688525396313|validation cost 7.843412507251025\n",
      "b: 4.456325525633002\n",
      "epochs 647/1000:\n",
      "training cost 6.361844584631814|validation cost 7.83392899746161\n",
      "b: 4.456449008454868\n",
      "epochs 648/1000:\n",
      "training cost 6.35302583355153|validation cost 7.82447030704449\n",
      "b: 4.45657139227962\n",
      "epochs 649/1000:\n",
      "training cost 6.3442321687801195|validation cost 7.815036342852761\n",
      "b: 4.456692686888331\n",
      "epochs 650/1000:\n",
      "training cost 6.3354634875277425|validation cost 7.805627012238301\n",
      "b: 4.4568129019750256\n",
      "epochs 651/1000:\n",
      "training cost 6.326719687585608|validation cost 7.796242223048012\n",
      "b: 4.456932047147448\n",
      "epochs 652/1000:\n",
      "training cost 6.3180006673215745|validation cost 7.786881883620109\n",
      "b: 4.4570501319278355\n",
      "epochs 653/1000:\n",
      "training cost 6.3093063256757915|validation cost 7.7775459027804335\n",
      "b: 4.4571671657536776\n",
      "epochs 654/1000:\n",
      "training cost 6.300636562156374|validation cost 7.768234189838819\n",
      "b: 4.45728315797847\n",
      "epochs 655/1000:\n",
      "training cost 6.291991276835134|validation cost 7.758946654585475\n",
      "b: 4.4573981178724615\n",
      "epochs 656/1000:\n",
      "training cost 6.283370370343344|validation cost 7.749683207287421\n",
      "b: 4.457512054623397\n",
      "epochs 657/1000:\n",
      "training cost 6.27477374386754|validation cost 7.740443758684955\n",
      "b: 4.4576249773372485\n",
      "epochs 658/1000:\n",
      "training cost 6.26620129914537|validation cost 7.731228219988135\n",
      "b: 4.457736895038947\n",
      "epochs 659/1000:\n",
      "training cost 6.2576529384614785|validation cost 7.722036502873331\n",
      "b: 4.4578478166731\n",
      "epochs 660/1000:\n",
      "training cost 6.249128564643434|validation cost 7.712868519479773\n",
      "b: 4.4579577511047095\n",
      "epochs 661/1000:\n",
      "training cost 6.240628081057685|validation cost 7.703724182406162\n",
      "b: 4.458066707119878\n",
      "epochs 662/1000:\n",
      "training cost 6.232151391605574|validation cost 7.6946034047073\n",
      "b: 4.4581746934265105\n",
      "epochs 663/1000:\n",
      "training cost 6.223698400719365|validation cost 7.685506099890743\n",
      "b: 4.458281718655015\n",
      "epochs 664/1000:\n",
      "training cost 6.2152690133583315|validation cost 7.67643218191352\n",
      "b: 4.4583877913589856\n",
      "epochs 665/1000:\n",
      "training cost 6.206863135004864|validation cost 7.667381565178835\n",
      "b: 4.458492920015891\n",
      "epochs 666/1000:\n",
      "training cost 6.198480671660628|validation cost 7.6583541645328514\n",
      "b: 4.458597113027749\n",
      "epochs 667/1000:\n",
      "training cost 6.1901215298427426|validation cost 7.649349895261464\n",
      "b: 4.458700378721802\n",
      "epochs 668/1000:\n",
      "training cost 6.181785616580011|validation cost 7.640368673087133\n",
      "b: 4.458802725351178\n",
      "epochs 669/1000:\n",
      "training cost 6.173472839409177|validation cost 7.631410414165736\n",
      "b: 4.458904161095552\n",
      "epochs 670/1000:\n",
      "training cost 6.165183106371222|validation cost 7.622475035083431\n",
      "b: 4.459004694061802\n",
      "epochs 671/1000:\n",
      "training cost 6.156916326007685|validation cost 7.613562452853598\n",
      "b: 4.459104332284652\n",
      "epochs 672/1000:\n",
      "training cost 6.148672407357033|validation cost 7.604672584913759\n",
      "b: 4.459203083727319\n",
      "epochs 673/1000:\n",
      "training cost 6.140451259951053|validation cost 7.595805349122552\n",
      "b: 4.459300956282146\n",
      "epochs 674/1000:\n",
      "training cost 6.132252793811291|validation cost 7.586960663756732\n",
      "b: 4.459397957771235\n",
      "epochs 675/1000:\n",
      "training cost 6.124076919445497|validation cost 7.578138447508196\n",
      "b: 4.459494095947071\n",
      "epochs 676/1000:\n",
      "training cost 6.115923547844141|validation cost 7.569338619481039\n",
      "b: 4.459589378493142\n",
      "epochs 677/1000:\n",
      "training cost 6.107792590476928|validation cost 7.560561099188641\n",
      "b: 4.459683813024553\n",
      "epochs 678/1000:\n",
      "training cost 6.0996839592893615|validation cost 7.551805806550764\n",
      "b: 4.459777407088634\n",
      "epochs 679/1000:\n",
      "training cost 6.091597566699337|validation cost 7.543072661890698\n",
      "b: 4.459870168165545\n",
      "epochs 680/1000:\n",
      "training cost 6.083533325593761|validation cost 7.534361585932429\n",
      "b: 4.459962103668872\n",
      "epochs 681/1000:\n",
      "training cost 6.07549114932521|validation cost 7.525672499797815\n",
      "b: 4.460053220946219\n",
      "epochs 682/1000:\n",
      "training cost 6.067470951708614|validation cost 7.5170053250038125\n",
      "b: 4.460143527279798\n",
      "epochs 683/1000:\n",
      "training cost 6.059472647017962|validation cost 7.508359983459718\n",
      "b: 4.460233029887008\n",
      "epochs 684/1000:\n",
      "training cost 6.051496149983064|validation cost 7.49973639746443\n",
      "b: 4.460321735921013\n",
      "epochs 685/1000:\n",
      "training cost 6.043541375786309|validation cost 7.491134489703743\n",
      "b: 4.460409652471316\n",
      "epochs 686/1000:\n",
      "training cost 6.035608240059478|validation cost 7.482554183247668\n",
      "b: 4.460496786564321\n",
      "epochs 687/1000:\n",
      "training cost 6.027696658880572|validation cost 7.473995401547774\n",
      "b: 4.460583145163898\n",
      "epochs 688/1000:\n",
      "training cost 6.019806548770672|validation cost 7.465458068434548\n",
      "b: 4.460668735171939\n",
      "epochs 689/1000:\n",
      "training cost 6.011937826690837|validation cost 7.456942108114798\n",
      "b: 4.460753563428909\n",
      "epochs 690/1000:\n",
      "training cost 6.00409041003901|validation cost 7.4484474451690525\n",
      "b: 4.460837636714392\n",
      "epochs 691/1000:\n",
      "training cost 5.996264216646969|validation cost 7.4399740045490095\n",
      "b: 4.460920961747634\n",
      "epochs 692/1000:\n",
      "training cost 5.9884591647773|validation cost 7.431521711574993\n",
      "b: 4.46100354518808\n",
      "epochs 693/1000:\n",
      "training cost 5.980675173120393|validation cost 7.423090491933442\n",
      "b: 4.461085393635907\n",
      "epochs 694/1000:\n",
      "training cost 5.972912160791473|validation cost 7.414680271674406\n",
      "b: 4.461166513632548\n",
      "epochs 695/1000:\n",
      "training cost 5.965170047327642|validation cost 7.406290977209089\n",
      "b: 4.461246911661218\n",
      "epochs 696/1000:\n",
      "training cost 5.957448752684979|validation cost 7.397922535307396\n",
      "b: 4.461326594147433\n",
      "epochs 697/1000:\n",
      "training cost 5.949748197235619|validation cost 7.389574873095497\n",
      "b: 4.461405567459521\n",
      "epochs 698/1000:\n",
      "training cost 5.942068301764902|validation cost 7.381247918053439\n",
      "b: 4.461483837909132\n",
      "epochs 699/1000:\n",
      "training cost 5.934408987468527|validation cost 7.372941598012754\n",
      "b: 4.461561411751741\n",
      "epochs 700/1000:\n",
      "training cost 5.926770175949719|validation cost 7.3646558411540965\n",
      "b: 4.46163829518715\n",
      "epochs 701/1000:\n",
      "training cost 5.919151789216452|validation cost 7.356390576004907\n",
      "b: 4.461714494359985\n",
      "epochs 702/1000:\n",
      "training cost 5.911553749678672|validation cost 7.348145731437093\n",
      "b: 4.46179001536018\n",
      "epochs 703/1000:\n",
      "training cost 5.903975980145549|validation cost 7.339921236664724\n",
      "b: 4.461864864223474\n",
      "epochs 704/1000:\n",
      "training cost 5.896418403822761|validation cost 7.33171702124176\n",
      "b: 4.461939046931885\n",
      "epochs 705/1000:\n",
      "training cost 5.888880944309796|validation cost 7.323533015059787\n",
      "b: 4.462012569414191\n",
      "epochs 706/1000:\n",
      "training cost 5.88136352559727|validation cost 7.315369148345784\n",
      "b: 4.4620854375464045\n",
      "epochs 707/1000:\n",
      "training cost 5.873866072064288|validation cost 7.307225351659896\n",
      "b: 4.462157657152241\n",
      "epochs 708/1000:\n",
      "training cost 5.86638850847581|validation cost 7.299101555893252\n",
      "b: 4.462229234003586\n",
      "epochs 709/1000:\n",
      "training cost 5.858930759980044|validation cost 7.290997692265764\n",
      "b: 4.462300173820954\n",
      "epochs 710/1000:\n",
      "training cost 5.8514927521058695|validation cost 7.282913692323976\n",
      "b: 4.462370482273948\n",
      "epochs 711/1000:\n",
      "training cost 5.844074410760274|validation cost 7.274849487938922\n",
      "b: 4.46244016498171\n",
      "epochs 712/1000:\n",
      "training cost 5.8366756622258125|validation cost 7.266805011304004\n",
      "b: 4.462509227513372\n",
      "epochs 713/1000:\n",
      "training cost 5.829296433158102|validation cost 7.2587801949328865\n",
      "b: 4.462577675388504\n",
      "epochs 714/1000:\n",
      "training cost 5.821936650583307|validation cost 7.250774971657402\n",
      "b: 4.462645514077546\n",
      "epochs 715/1000:\n",
      "training cost 5.814596241895694|validation cost 7.242789274625497\n",
      "b: 4.462712749002256\n",
      "epochs 716/1000:\n",
      "training cost 5.807275134855151|validation cost 7.234823037299168\n",
      "b: 4.462779385536136\n",
      "epochs 717/1000:\n",
      "training cost 5.799973257584779|validation cost 7.226876193452432\n",
      "b: 4.462845429004864\n",
      "epochs 718/1000:\n",
      "training cost 5.792690538568465|validation cost 7.218948677169325\n",
      "b: 4.462910884686721\n",
      "epochs 719/1000:\n",
      "training cost 5.785426906648507|validation cost 7.211040422841879\n",
      "b: 4.462975757813009\n",
      "epochs 720/1000:\n",
      "training cost 5.7781822910232306|validation cost 7.2031513651681545\n",
      "b: 4.4630400535684736\n",
      "epochs 721/1000:\n",
      "training cost 5.770956621244649|validation cost 7.1952814391502855\n",
      "b: 4.463103777091714\n",
      "epochs 722/1000:\n",
      "training cost 5.763749827216131|validation cost 7.187430580092513\n",
      "b: 4.4631669334755975\n",
      "epochs 723/1000:\n",
      "training cost 5.756561839190091|validation cost 7.1795987235992715\n",
      "b: 4.463229527767664\n",
      "epochs 724/1000:\n",
      "training cost 5.749392587765693|validation cost 7.1717858055732595\n",
      "b: 4.4632915649705325\n",
      "epochs 725/1000:\n",
      "training cost 5.7422420038865924|validation cost 7.163991762213552\n",
      "b: 4.463353050042294\n",
      "epochs 726/1000:\n",
      "training cost 5.73511001883867|validation cost 7.156216530013716\n",
      "b: 4.463413987896918\n",
      "epochs 727/1000:\n",
      "training cost 5.727996564247806|validation cost 7.148460045759949\n",
      "b: 4.463474383404636\n",
      "epochs 728/1000:\n",
      "training cost 5.720901572077664|validation cost 7.1407222465292115\n",
      "b: 4.463534241392335\n",
      "epochs 729/1000:\n",
      "training cost 5.713824974627497|validation cost 7.133003069687418\n",
      "b: 4.463593566643943\n",
      "epochs 730/1000:\n",
      "training cost 5.706766704529967|validation cost 7.1253024528875875\n",
      "b: 4.463652363900811\n",
      "epochs 731/1000:\n",
      "training cost 5.699726694748981|validation cost 7.117620334068072\n",
      "b: 4.4637106378620945\n",
      "epochs 732/1000:\n",
      "training cost 5.692704878577561|validation cost 7.1099566514507435\n",
      "b: 4.463768393185122\n",
      "epochs 733/1000:\n",
      "training cost 5.685701189635711|validation cost 7.1023113435392276\n",
      "b: 4.463825634485774\n",
      "epochs 734/1000:\n",
      "training cost 5.678715561868308|validation cost 7.094684349117143\n",
      "b: 4.463882366338851\n",
      "epochs 735/1000:\n",
      "training cost 5.671747929543022|validation cost 7.0870756072463585\n",
      "b: 4.463938593278435\n",
      "epochs 736/1000:\n",
      "training cost 5.664798227248239|validation cost 7.079485057265268\n",
      "b: 4.463994319798257\n",
      "epochs 737/1000:\n",
      "training cost 5.657866389891006|validation cost 7.07191263878706\n",
      "b: 4.464049550352052\n",
      "epochs 738/1000:\n",
      "training cost 5.650952352694994|validation cost 7.064358291698028\n",
      "b: 4.4641042893539185\n",
      "epochs 739/1000:\n",
      "training cost 5.644056051198476|validation cost 7.056821956155882\n",
      "b: 4.464158541178668\n",
      "epochs 740/1000:\n",
      "training cost 5.6371774212523205|validation cost 7.049303572588065\n",
      "b: 4.4642123101621785\n",
      "epochs 741/1000:\n",
      "training cost 5.630316399018009|validation cost 7.041803081690107\n",
      "b: 4.464265600601735\n",
      "epochs 742/1000:\n",
      "training cost 5.623472920965657|validation cost 7.034320424423961\n",
      "b: 4.464318416756379\n",
      "epochs 743/1000:\n",
      "training cost 5.616646923872062|validation cost 7.02685554201639\n",
      "b: 4.464370762847247\n",
      "epochs 744/1000:\n",
      "training cost 5.60983834481876|validation cost 7.019408375957335\n",
      "b: 4.464422643057907\n",
      "epochs 745/1000:\n",
      "training cost 5.603047121190104|validation cost 7.011978867998302\n",
      "b: 4.464474061534692\n",
      "epochs 746/1000:\n",
      "training cost 5.596273190671356|validation cost 7.004566960150791\n",
      "b: 4.464525022387034\n",
      "epochs 747/1000:\n",
      "training cost 5.589516491246783|validation cost 6.997172594684687\n",
      "b: 4.464575529687789\n",
      "epochs 748/1000:\n",
      "training cost 5.582776961197798|validation cost 6.989795714126714\n",
      "b: 4.464625587473567\n",
      "epochs 749/1000:\n",
      "training cost 5.576054539101075|validation cost 6.982436261258876\n",
      "b: 4.464675199745052\n",
      "epochs 750/1000:\n",
      "training cost 5.569349163826715|validation cost 6.9750941791168986\n",
      "b: 4.464724370467321\n",
      "epochs 751/1000:\n",
      "training cost 5.5626607745364085|validation cost 6.967769410988719\n",
      "b: 4.464773103570162\n",
      "epochs 752/1000:\n",
      "training cost 5.555989310681615|validation cost 6.960461900412956\n",
      "b: 4.464821402948388\n",
      "epochs 753/1000:\n",
      "training cost 5.549334712001761|validation cost 6.953171591177413\n",
      "b: 4.464869272462147\n",
      "epochs 754/1000:\n",
      "training cost 5.54269691852245|validation cost 6.945898427317571\n",
      "b: 4.4649167159372345\n",
      "epochs 755/1000:\n",
      "training cost 5.536075870553682|validation cost 6.938642353115121\n",
      "b: 4.464963737165393\n",
      "epochs 756/1000:\n",
      "training cost 5.529471508688097|validation cost 6.9314033130964825\n",
      "b: 4.46501033990462\n",
      "epochs 757/1000:\n",
      "training cost 5.52288377379923|validation cost 6.92418125203135\n",
      "b: 4.46505652787947\n",
      "epochs 758/1000:\n",
      "training cost 5.5163126070397634|validation cost 6.9169761149312485\n",
      "b: 4.465102304781342\n",
      "epochs 759/1000:\n",
      "training cost 5.509757949839823|validation cost 6.9097878470481\n",
      "b: 4.465147674268788\n",
      "epochs 760/1000:\n",
      "training cost 5.503219743905265|validation cost 6.902616393872782\n",
      "b: 4.465192639967796\n",
      "epochs 761/1000:\n",
      "training cost 5.496697931215978|validation cost 6.895461701133735\n",
      "b: 4.465237205472083\n",
      "epochs 762/1000:\n",
      "training cost 5.490192454024209|validation cost 6.888323714795555\n",
      "b: 4.465281374343381\n",
      "epochs 763/1000:\n",
      "training cost 5.483703254852894|validation cost 6.881202381057598\n",
      "b: 4.465325150111725\n",
      "epochs 764/1000:\n",
      "training cost 5.477230276494006|validation cost 6.8740976463526025\n",
      "b: 4.46536853627573\n",
      "epochs 765/1000:\n",
      "training cost 5.4707734620069095|validation cost 6.86700945734532\n",
      "b: 4.465411536302876\n",
      "epochs 766/1000:\n",
      "training cost 5.464332754716743|validation cost 6.859937760931157\n",
      "b: 4.465454153629781\n",
      "epochs 767/1000:\n",
      "training cost 5.457908098212789|validation cost 6.852882504234824\n",
      "b: 4.465496391662476\n",
      "epochs 768/1000:\n",
      "training cost 5.45149943634688|validation cost 6.845843634609008\n",
      "b: 4.465538253776679\n",
      "epochs 769/1000:\n",
      "training cost 5.445106713231808|validation cost 6.838821099633038\n",
      "b: 4.465579743318067\n",
      "epochs 770/1000:\n",
      "training cost 5.438729873239747|validation cost 6.831814847111561\n",
      "b: 4.465620863602536\n",
      "epochs 771/1000:\n",
      "training cost 5.432368861000682|validation cost 6.824824825073249\n",
      "b: 4.465661617916473\n",
      "epochs 772/1000:\n",
      "training cost 5.426023621400855|validation cost 6.817850981769496\n",
      "b: 4.465702009517017\n",
      "epochs 773/1000:\n",
      "training cost 5.419694099581233|validation cost 6.8108932656731245\n",
      "b: 4.465742041632315\n",
      "epochs 774/1000:\n",
      "training cost 5.413380240935963|validation cost 6.803951625477124\n",
      "b: 4.4657817174617875\n",
      "epochs 775/1000:\n",
      "training cost 5.407081991110868|validation cost 6.797026010093376\n",
      "b: 4.465821040176378\n",
      "epochs 776/1000:\n",
      "training cost 5.40079929600193|validation cost 6.790116368651388\n",
      "b: 4.465860012918808\n",
      "epochs 777/1000:\n",
      "training cost 5.394532101753798|validation cost 6.783222650497064\n",
      "b: 4.465898638803831\n",
      "epochs 778/1000:\n",
      "training cost 5.388280354758307|validation cost 6.7763448051914486\n",
      "b: 4.465936920918478\n",
      "epochs 779/1000:\n",
      "training cost 5.382044001653001|validation cost 6.769482782509511\n",
      "b: 4.4659748623223035\n",
      "epochs 780/1000:\n",
      "training cost 5.375822989319674|validation cost 6.7626365324389175\n",
      "b: 4.466012466047635\n",
      "epochs 781/1000:\n",
      "training cost 5.369617264882918|validation cost 6.755806005178823\n",
      "b: 4.466049735099811\n",
      "epochs 782/1000:\n",
      "training cost 5.363426775708685|validation cost 6.748991151138675\n",
      "b: 4.466086672457423\n",
      "epochs 783/1000:\n",
      "training cost 5.357251469402863|validation cost 6.742191920937013\n",
      "b: 4.4661232810725515\n",
      "epochs 784/1000:\n",
      "training cost 5.351091293809845|validation cost 6.735408265400288\n",
      "b: 4.466159563871006\n",
      "epochs 785/1000:\n",
      "training cost 5.344946197011138|validation cost 6.728640135561697\n",
      "b: 4.466195523752554\n",
      "epochs 786/1000:\n",
      "training cost 5.338816127323957|validation cost 6.721887482660001\n",
      "b: 4.466231163591156\n",
      "epochs 787/1000:\n",
      "training cost 5.332701033299839|validation cost 6.715150258138386\n",
      "b: 4.466266486235195\n",
      "epochs 788/1000:\n",
      "training cost 5.326600863723274|validation cost 6.7084284136433\n",
      "b: 4.466301494507702\n",
      "epochs 789/1000:\n",
      "training cost 5.3205155676103315|validation cost 6.701721901023321\n",
      "b: 4.466336191206583\n",
      "epochs 790/1000:\n",
      "training cost 5.314445094207313|validation cost 6.695030672328026\n",
      "b: 4.4663705791048445\n",
      "epochs 791/1000:\n",
      "training cost 5.308389392989398|validation cost 6.688354679806864\n",
      "b: 4.466404660950811\n",
      "epochs 792/1000:\n",
      "training cost 5.302348413659323|validation cost 6.681693875908041\n",
      "b: 4.466438439468349\n",
      "epochs 793/1000:\n",
      "training cost 5.296322106146037|validation cost 6.675048213277427\n",
      "b: 4.46647191735708\n",
      "epochs 794/1000:\n",
      "training cost 5.290310420603407|validation cost 6.6684176447574375\n",
      "b: 4.466505097292602\n",
      "epochs 795/1000:\n",
      "training cost 5.284313307408894|validation cost 6.661802123385956\n",
      "b: 4.466537981926698\n",
      "epochs 796/1000:\n",
      "training cost 5.278330717162273|validation cost 6.655201602395254\n",
      "b: 4.466570573887551\n",
      "epochs 797/1000:\n",
      "training cost 5.272362600684335|validation cost 6.648616035210906\n",
      "b: 4.466602875779952\n",
      "epochs 798/1000:\n",
      "training cost 5.266408909015615|validation cost 6.642045375450734\n",
      "b: 4.46663489018551\n",
      "epochs 799/1000:\n",
      "training cost 5.260469593415125|validation cost 6.63548957692374\n",
      "b: 4.466666619662859\n",
      "epochs 800/1000:\n",
      "training cost 5.254544605359093|validation cost 6.628948593629069\n",
      "b: 4.46669806674786\n",
      "epochs 801/1000:\n",
      "training cost 5.248633896539717|validation cost 6.622422379754945\n",
      "b: 4.466729233953804\n",
      "epochs 802/1000:\n",
      "training cost 5.242737418863927|validation cost 6.615910889677653\n",
      "b: 4.466760123771615\n",
      "epochs 803/1000:\n",
      "training cost 5.236855124452143|validation cost 6.609414077960508\n",
      "b: 4.466790738670047\n",
      "epochs 804/1000:\n",
      "training cost 5.23098696563707|validation cost 6.602931899352826\n",
      "b: 4.466821081095884\n",
      "epochs 805/1000:\n",
      "training cost 5.225132894962473|validation cost 6.596464308788919\n",
      "b: 4.46685115347413\n",
      "epochs 806/1000:\n",
      "training cost 5.219292865181973|validation cost 6.590011261387085\n",
      "b: 4.46688095820821\n",
      "epochs 807/1000:\n",
      "training cost 5.21346682925786|validation cost 6.583572712448613\n",
      "b: 4.466910497680157\n",
      "epochs 808/1000:\n",
      "training cost 5.207654740359899|validation cost 6.577148617456786\n",
      "b: 4.466939774250804\n",
      "epochs 809/1000:\n",
      "training cost 5.201856551864153|validation cost 6.570738932075899\n",
      "b: 4.466968790259972\n",
      "epochs 810/1000:\n",
      "training cost 5.196072217351816|validation cost 6.564343612150285\n",
      "b: 4.466997548026658\n",
      "epochs 811/1000:\n",
      "training cost 5.190301690608046|validation cost 6.557962613703335\n",
      "b: 4.4670260498492205\n",
      "epochs 812/1000:\n",
      "training cost 5.184544925620823|validation cost 6.551595892936553\n",
      "b: 4.4670542980055625\n",
      "epochs 813/1000:\n",
      "training cost 5.178801876579791|validation cost 6.545243406228573\n",
      "b: 4.467082294753313\n",
      "epochs 814/1000:\n",
      "training cost 5.17307249787513|validation cost 6.538905110134228\n",
      "b: 4.467110042330009\n",
      "epochs 815/1000:\n",
      "training cost 5.167356744096427|validation cost 6.532580961383608\n",
      "b: 4.467137542953272\n",
      "epochs 816/1000:\n",
      "training cost 5.16165457003155|validation cost 6.526270916881108\n",
      "b: 4.4671647988209875\n",
      "epochs 817/1000:\n",
      "training cost 5.155965930665545|validation cost 6.519974933704514\n",
      "b: 4.467191812111481\n",
      "epochs 818/1000:\n",
      "training cost 5.150290781179523|validation cost 6.51369296910407\n",
      "b: 4.467218584983689\n",
      "epochs 819/1000:\n",
      "training cost 5.14462907694957|validation cost 6.507424980501562\n",
      "b: 4.467245119577334\n",
      "epochs 820/1000:\n",
      "training cost 5.138980773545652|validation cost 6.5011709254894114\n",
      "b: 4.4672714180130955\n",
      "epochs 821/1000:\n",
      "training cost 5.133345826730539|validation cost 6.494930761829768\n",
      "b: 4.4672974823927785\n",
      "epochs 822/1000:\n",
      "training cost 5.127724192458729|validation cost 6.488704447453614\n",
      "b: 4.467323314799483\n",
      "epochs 823/1000:\n",
      "training cost 5.12211582687538|validation cost 6.48249194045987\n",
      "b: 4.467348917297768\n",
      "epochs 824/1000:\n",
      "training cost 5.116520686315262|validation cost 6.476293199114509\n",
      "b: 4.467374291933818\n",
      "epochs 825/1000:\n",
      "training cost 5.110938727301691|validation cost 6.470108181849684\n",
      "b: 4.467399440735607\n",
      "epochs 826/1000:\n",
      "training cost 5.105369906545497|validation cost 6.463936847262847\n",
      "b: 4.46742436571306\n",
      "epochs 827/1000:\n",
      "training cost 5.099814180943984|validation cost 6.457779154115879\n",
      "b: 4.467449068858214\n",
      "epochs 828/1000:\n",
      "training cost 5.094271507579897|validation cost 6.451635061334243\n",
      "b: 4.467473552145376\n",
      "epochs 829/1000:\n",
      "training cost 5.088741843720408|validation cost 6.445504528006114\n",
      "b: 4.467497817531282\n",
      "epochs 830/1000:\n",
      "training cost 5.083225146816095|validation cost 6.439387513381542\n",
      "b: 4.467521866955253\n",
      "epochs 831/1000:\n",
      "training cost 5.077721374499936|validation cost 6.433283976871597\n",
      "b: 4.467545702339351\n",
      "epochs 832/1000:\n",
      "training cost 5.072230484586315|validation cost 6.427193878047537\n",
      "b: 4.467569325588531\n",
      "epochs 833/1000:\n",
      "training cost 5.066752435070015|validation cost 6.421117176639981\n",
      "b: 4.467592738590794\n",
      "epochs 834/1000:\n",
      "training cost 5.0612871841252405|validation cost 6.415053832538069\n",
      "b: 4.467615943217336\n",
      "epochs 835/1000:\n",
      "training cost 5.055834690104637|validation cost 6.409003805788655\n",
      "b: 4.467638941322702\n",
      "epochs 836/1000:\n",
      "training cost 5.05039491153832|validation cost 6.402967056595483\n",
      "b: 4.4676617347449294\n",
      "epochs 837/1000:\n",
      "training cost 5.0449678071329|validation cost 6.396943545318388\n",
      "b: 4.4676843253057\n",
      "epochs 838/1000:\n",
      "training cost 5.039553335770526|validation cost 6.390933232472479\n",
      "b: 4.467706714810479\n",
      "epochs 839/1000:\n",
      "training cost 5.0341514565079395|validation cost 6.38493607872734\n",
      "b: 4.4677289050486655\n",
      "epochs 840/1000:\n",
      "training cost 5.028762128575518|validation cost 6.3789520449062564\n",
      "b: 4.467750897793732\n",
      "epochs 841/1000:\n",
      "training cost 5.023385311376342|validation cost 6.372981091985404\n",
      "b: 4.467772694803368\n",
      "epochs 842/1000:\n",
      "training cost 5.018020964485257|validation cost 6.367023181093079\n",
      "b: 4.4677942978196175\n",
      "epochs 843/1000:\n",
      "training cost 5.012669047647946|validation cost 6.361078273508913\n",
      "b: 4.467815708569023\n",
      "epochs 844/1000:\n",
      "training cost 5.007329520780012|validation cost 6.355146330663114\n",
      "b: 4.467836928762758\n",
      "epochs 845/1000:\n",
      "training cost 5.00200234396606|validation cost 6.349227314135684\n",
      "b: 4.46785796009677\n",
      "epochs 846/1000:\n",
      "training cost 4.996687477458787|validation cost 6.343321185655662\n",
      "b: 4.467878804251908\n",
      "epochs 847/1000:\n",
      "training cost 4.991384881678085|validation cost 6.3374279071003725\n",
      "b: 4.467899462894066\n",
      "epochs 848/1000:\n",
      "training cost 4.986094517210141|validation cost 6.331547440494676\n",
      "b: 4.467919937674309\n",
      "epochs 849/1000:\n",
      "training cost 4.980816344806546|validation cost 6.325679748010201\n",
      "b: 4.467940230229008\n",
      "epochs 850/1000:\n",
      "training cost 4.975550325383411|validation cost 6.319824791964634\n",
      "b: 4.467960342179969\n",
      "epochs 851/1000:\n",
      "training cost 4.9702964200204915|validation cost 6.3139825348209495\n",
      "b: 4.467980275134567\n",
      "epochs 852/1000:\n",
      "training cost 4.965054589960314|validation cost 6.3081529391867095\n",
      "b: 4.46800003068587\n",
      "epochs 853/1000:\n",
      "training cost 4.959824796607304|validation cost 6.302335967813313\n",
      "b: 4.468019610412766\n",
      "epochs 854/1000:\n",
      "training cost 4.954607001526936|validation cost 6.29653158359528\n",
      "b: 4.468039015880092\n",
      "epochs 855/1000:\n",
      "training cost 4.9494011664448685|validation cost 6.290739749569545\n",
      "b: 4.4680582486387594\n",
      "epochs 856/1000:\n",
      "training cost 4.944207253246099|validation cost 6.284960428914724\n",
      "b: 4.468077310225874\n",
      "epochs 857/1000:\n",
      "training cost 4.93902522397412|validation cost 6.279193584950422\n",
      "b: 4.4680962021648645\n",
      "epochs 858/1000:\n",
      "training cost 4.933855040830083|validation cost 6.273439181136521\n",
      "b: 4.4681149259655975\n",
      "epochs 859/1000:\n",
      "training cost 4.9286966661719624|validation cost 6.267697181072483\n",
      "b: 4.468133483124504\n",
      "epochs 860/1000:\n",
      "training cost 4.92355006251373|validation cost 6.261967548496665\n",
      "b: 4.468151875124696\n",
      "epochs 861/1000:\n",
      "training cost 4.918415192524537|validation cost 6.256250247285607\n",
      "b: 4.468170103436086\n",
      "epochs 862/1000:\n",
      "training cost 4.913292019027891|validation cost 6.250545241453368\n",
      "b: 4.468188169515505\n",
      "epochs 863/1000:\n",
      "training cost 4.908180505000854|validation cost 6.244852495150833\n",
      "b: 4.468206074806817\n",
      "epochs 864/1000:\n",
      "training cost 4.903080613573228|validation cost 6.23917197266504\n",
      "b: 4.468223820741036\n",
      "epochs 865/1000:\n",
      "training cost 4.8979923080267636|validation cost 6.233503638418506\n",
      "b: 4.468241408736441\n",
      "epochs 866/1000:\n",
      "training cost 4.892915551794359|validation cost 6.227847456968563\n",
      "b: 4.468258840198687\n",
      "epochs 867/1000:\n",
      "training cost 4.887850308459278|validation cost 6.222203393006687\n",
      "b: 4.468276116520919\n",
      "epochs 868/1000:\n",
      "training cost 4.882796541754354|validation cost 6.216571411357847\n",
      "b: 4.4682932390838825\n",
      "epochs 869/1000:\n",
      "training cost 4.877754215561226|validation cost 6.210951476979842\n",
      "b: 4.468310209256036\n",
      "epochs 870/1000:\n",
      "training cost 4.87272329390955|validation cost 6.205343554962654\n",
      "b: 4.468327028393658\n",
      "epochs 871/1000:\n",
      "training cost 4.867703740976239|validation cost 6.1997476105277975\n",
      "b: 4.468343697840954\n",
      "epochs 872/1000:\n",
      "training cost 4.8626955210846985|validation cost 6.194163609027687\n",
      "b: 4.46836021893017\n",
      "epochs 873/1000:\n",
      "training cost 4.8576985987040615|validation cost 6.188591515944982\n",
      "b: 4.468376592981691\n",
      "epochs 874/1000:\n",
      "training cost 4.852712938448446|validation cost 6.183031296891969\n",
      "b: 4.468392821304154\n",
      "epochs 875/1000:\n",
      "training cost 4.847738505076192|validation cost 6.177482917609916\n",
      "b: 4.468408905194547\n",
      "epochs 876/1000:\n",
      "training cost 4.842775263489127|validation cost 6.1719463439684565\n",
      "b: 4.468424845938316\n",
      "epochs 877/1000:\n",
      "training cost 4.837823178731822|validation cost 6.16642154196496\n",
      "b: 4.468440644809465\n",
      "epochs 878/1000:\n",
      "training cost 4.832882215990861|validation cost 6.160908477723918\n",
      "b: 4.468456303070661\n",
      "epochs 879/1000:\n",
      "training cost 4.827952340594106|validation cost 6.15540711749633\n",
      "b: 4.468471821973332\n",
      "epochs 880/1000:\n",
      "training cost 4.823033518009974|validation cost 6.14991742765908\n",
      "b: 4.468487202757769\n",
      "epochs 881/1000:\n",
      "training cost 4.818125713846721|validation cost 6.144439374714354\n",
      "b: 4.4685024466532255\n",
      "epochs 882/1000:\n",
      "training cost 4.813228893851715|validation cost 6.138972925289006\n",
      "b: 4.468517554878011\n",
      "epochs 883/1000:\n",
      "training cost 4.808343023910737|validation cost 6.133518046133984\n",
      "b: 4.468532528639597\n",
      "epochs 884/1000:\n",
      "training cost 4.803468070047267|validation cost 6.12807470412372\n",
      "b: 4.468547369134704\n",
      "epochs 885/1000:\n",
      "training cost 4.798603998421782|validation cost 6.1226428662555445\n",
      "b: 4.4685620775494055\n",
      "epochs 886/1000:\n",
      "training cost 4.793750775331061|validation cost 6.117222499649089\n",
      "b: 4.468576655059215\n",
      "epochs 887/1000:\n",
      "training cost 4.7889083672074895|validation cost 6.111813571545716\n",
      "b: 4.468591102829189\n",
      "epochs 888/1000:\n",
      "training cost 4.784076740618374|validation cost 6.106416049307925\n",
      "b: 4.468605422014009\n",
      "epochs 889/1000:\n",
      "training cost 4.77925586226525|validation cost 6.101029900418778\n",
      "b: 4.468619613758084\n",
      "epochs 890/1000:\n",
      "training cost 4.774445698983212|validation cost 6.095655092481327\n",
      "b: 4.468633679195637\n",
      "epochs 891/1000:\n",
      "training cost 4.769646217740227|validation cost 6.090291593218047\n",
      "b: 4.468647619450796\n",
      "epochs 892/1000:\n",
      "training cost 4.764857385636473|validation cost 6.084939370470258\n",
      "b: 4.468661435637684\n",
      "epochs 893/1000:\n",
      "training cost 4.760079169903664|validation cost 6.079598392197575\n",
      "b: 4.468675128860509\n",
      "epochs 894/1000:\n",
      "training cost 4.755311537904388|validation cost 6.0742686264773385\n",
      "b: 4.468688700213651\n",
      "epochs 895/1000:\n",
      "training cost 4.750554457131456|validation cost 6.06895004150406\n",
      "b: 4.468702150781749\n",
      "epochs 896/1000:\n",
      "training cost 4.7458078952072364|validation cost 6.063642605588874\n",
      "b: 4.468715481639792\n",
      "epochs 897/1000:\n",
      "training cost 4.7410718198830075|validation cost 6.058346287158974\n",
      "b: 4.468728693853198\n",
      "epochs 898/1000:\n",
      "training cost 4.736346199038313|validation cost 6.053061054757088\n",
      "b: 4.468741788477904\n",
      "epochs 899/1000:\n",
      "training cost 4.731631000680321|validation cost 6.047786877040916\n",
      "b: 4.46875476656045\n",
      "epochs 900/1000:\n",
      "training cost 4.726926192943183|validation cost 6.042523722782592\n",
      "b: 4.468767629138062\n",
      "epochs 901/1000:\n",
      "training cost 4.722231744087394|validation cost 6.03727156086817\n",
      "b: 4.468780377238733\n",
      "epochs 902/1000:\n",
      "training cost 4.717547622499173|validation cost 6.032030360297056\n",
      "b: 4.468793011881308\n",
      "epochs 903/1000:\n",
      "training cost 4.712873796689828|validation cost 6.0268000901814975\n",
      "b: 4.468805534075565\n",
      "epochs 904/1000:\n",
      "training cost 4.708210235295136|validation cost 6.021580719746065\n",
      "b: 4.468817944822292\n",
      "epochs 905/1000:\n",
      "training cost 4.7035569070747245|validation cost 6.016372218327107\n",
      "b: 4.468830245113374\n",
      "epochs 906/1000:\n",
      "training cost 4.698913780911453|validation cost 6.011174555372238\n",
      "b: 4.468842435931864\n",
      "epochs 907/1000:\n",
      "training cost 4.694280825810809|validation cost 6.005987700439835\n",
      "b: 4.468854518252071\n",
      "epochs 908/1000:\n",
      "training cost 4.689658010900293|validation cost 6.0008116231985\n",
      "b: 4.468866493039627\n",
      "epochs 909/1000:\n",
      "training cost 4.685045305428815|validation cost 5.99564629342656\n",
      "b: 4.468878361251575\n",
      "epochs 910/1000:\n",
      "training cost 4.680442678766102|validation cost 5.990491681011566\n",
      "b: 4.468890123836435\n",
      "epochs 911/1000:\n",
      "training cost 4.675850100402094|validation cost 5.985347755949773\n",
      "b: 4.468901781734291\n",
      "epochs 912/1000:\n",
      "training cost 4.6712675399463555|validation cost 5.980214488345644\n",
      "b: 4.468913335876856\n",
      "epochs 913/1000:\n",
      "training cost 4.666694967127485|validation cost 5.9750918484113615\n",
      "b: 4.468924787187552\n",
      "epochs 914/1000:\n",
      "training cost 4.662132351792528|validation cost 5.969979806466306\n",
      "b: 4.468936136581583\n",
      "epochs 915/1000:\n",
      "training cost 4.6575796639063975|validation cost 5.964878332936595\n",
      "b: 4.468947384966007\n",
      "epochs 916/1000:\n",
      "training cost 4.653036873551297|validation cost 5.95978739835456\n",
      "b: 4.468958533239809\n",
      "epochs 917/1000:\n",
      "training cost 4.64850395092614|validation cost 5.954706973358288\n",
      "b: 4.468969582293975\n",
      "epochs 918/1000:\n",
      "training cost 4.643980866345984|validation cost 5.949637028691112\n",
      "b: 4.468980533011559\n",
      "epochs 919/1000:\n",
      "training cost 4.639467590241465|validation cost 5.944577535201146\n",
      "b: 4.4689913862677555\n",
      "epochs 920/1000:\n",
      "training cost 4.634964093158224|validation cost 5.939528463840804\n",
      "b: 4.469002142929972\n",
      "epochs 921/1000:\n",
      "training cost 4.630470345756353|validation cost 5.934489785666316\n",
      "b: 4.469012803857896\n",
      "epochs 922/1000:\n",
      "training cost 4.625986318809838|validation cost 5.929461471837259\n",
      "b: 4.469023369903561\n",
      "epochs 923/1000:\n",
      "training cost 4.621511983206001|validation cost 5.92444349361609\n",
      "b: 4.469033841911419\n",
      "epochs 924/1000:\n",
      "training cost 4.617047309944952|validation cost 5.919435822367672\n",
      "b: 4.469044220718407\n",
      "epochs 925/1000:\n",
      "training cost 4.612592270139039|validation cost 5.914438429558814\n",
      "b: 4.469054507154014\n",
      "epochs 926/1000:\n",
      "training cost 4.608146835012307|validation cost 5.909451286757801\n",
      "b: 4.469064702040343\n",
      "epochs 927/1000:\n",
      "training cost 4.603710975899958|validation cost 5.904474365633953\n",
      "b: 4.469074806192183\n",
      "epochs 928/1000:\n",
      "training cost 4.599284664247803|validation cost 5.899507637957135\n",
      "b: 4.469084820417073\n",
      "epochs 929/1000:\n",
      "training cost 4.594867871611747|validation cost 5.894551075597338\n",
      "b: 4.469094745515361\n",
      "epochs 930/1000:\n",
      "training cost 4.590460569657235|validation cost 5.8896046505242055\n",
      "b: 4.469104582280274\n",
      "epochs 931/1000:\n",
      "training cost 4.586062730158743|validation cost 5.884668334806591\n",
      "b: 4.4691143314979795\n",
      "epochs 932/1000:\n",
      "training cost 4.581674324999244|validation cost 5.879742100612112\n",
      "b: 4.4691239939476475\n",
      "epochs 933/1000:\n",
      "training cost 4.577295326169686|validation cost 5.8748259202067\n",
      "b: 4.469133570401514\n",
      "epochs 934/1000:\n",
      "training cost 4.572925705768476|validation cost 5.869919765954171\n",
      "b: 4.469143061624941\n",
      "epochs 935/1000:\n",
      "training cost 4.568565436000965|validation cost 5.8650236103157765\n",
      "b: 4.469152468376478\n",
      "epochs 936/1000:\n",
      "training cost 4.56421448917893|validation cost 5.860137425849766\n",
      "b: 4.469161791407927\n",
      "epochs 937/1000:\n",
      "training cost 4.559872837720074|validation cost 5.8552611852109635\n",
      "b: 4.469171031464397\n",
      "epochs 938/1000:\n",
      "training cost 4.555540454147512|validation cost 5.850394861150325\n",
      "b: 4.469180189284364\n",
      "epochs 939/1000:\n",
      "training cost 4.551217311089269|validation cost 5.845538426514519\n",
      "b: 4.469189265599733\n",
      "epochs 940/1000:\n",
      "training cost 4.546903381277782|validation cost 5.84069185424549\n",
      "b: 4.469198261135896\n",
      "epochs 941/1000:\n",
      "training cost 4.542598637549401|validation cost 5.835855117380045\n",
      "b: 4.4692071766117865\n",
      "epochs 942/1000:\n",
      "training cost 4.538303052843891|validation cost 5.831028189049423\n",
      "b: 4.469216012739942\n",
      "epochs 943/1000:\n",
      "training cost 4.534016600203951|validation cost 5.826211042478883\n",
      "b: 4.469224770226556\n",
      "epochs 944/1000:\n",
      "training cost 4.529739252774713|validation cost 5.821403650987277\n",
      "b: 4.46923344977154\n",
      "epochs 945/1000:\n",
      "training cost 4.525470983803262|validation cost 5.816605987986649\n",
      "b: 4.469242052068573\n",
      "epochs 946/1000:\n",
      "training cost 4.521211766638152|validation cost 5.81181802698181\n",
      "b: 4.4692505778051625\n",
      "epochs 947/1000:\n",
      "training cost 4.516961574728928|validation cost 5.807039741569939\n",
      "b: 4.469259027662696\n",
      "epochs 948/1000:\n",
      "training cost 4.512720381625646|validation cost 5.80227110544017\n",
      "b: 4.469267402316499\n",
      "epochs 949/1000:\n",
      "training cost 4.508488160978396|validation cost 5.797512092373179\n",
      "b: 4.469275702435882\n",
      "epochs 950/1000:\n",
      "training cost 4.504264886536837|validation cost 5.7927626762408\n",
      "b: 4.469283928684202\n",
      "epochs 951/1000:\n",
      "training cost 4.500050532149724|validation cost 5.788022831005606\n",
      "b: 4.469292081718913\n",
      "epochs 952/1000:\n",
      "training cost 4.495845071764442|validation cost 5.783292530720521\n",
      "b: 4.469300162191614\n",
      "epochs 953/1000:\n",
      "training cost 4.491648479426539|validation cost 5.778571749528421\n",
      "b: 4.469308170748109\n",
      "epochs 954/1000:\n",
      "training cost 4.487460729279273|validation cost 5.773860461661734\n",
      "b: 4.46931610802845\n",
      "epochs 955/1000:\n",
      "training cost 4.483281795563144|validation cost 5.7691586414420595\n",
      "b: 4.469323974666997\n",
      "epochs 956/1000:\n",
      "training cost 4.47911165261545|validation cost 5.764466263279772\n",
      "b: 4.4693317712924605\n",
      "epochs 957/1000:\n",
      "training cost 4.474950274869822|validation cost 5.7597833016736315\n",
      "b: 4.469339498527957\n",
      "epochs 958/1000:\n",
      "training cost 4.470797636855781|validation cost 5.755109731210401\n",
      "b: 4.469347156991058\n",
      "epochs 959/1000:\n",
      "training cost 4.466653713198288|validation cost 5.750445526564469\n",
      "b: 4.4693547472938375\n",
      "epochs 960/1000:\n",
      "training cost 4.462518478617299|validation cost 5.74579066249746\n",
      "b: 4.4693622700429225\n",
      "epochs 961/1000:\n",
      "training cost 4.458391907927324|validation cost 5.74114511385785\n",
      "b: 4.469369725839541\n",
      "epochs 962/1000:\n",
      "training cost 4.454273976036987|validation cost 5.7365088555806105\n",
      "b: 4.469377115279569\n",
      "epochs 963/1000:\n",
      "training cost 4.45016465794858|validation cost 5.731881862686808\n",
      "b: 4.469384438953581\n",
      "epochs 964/1000:\n",
      "training cost 4.446063928757642|validation cost 5.727264110283255\n",
      "b: 4.469391697446894\n",
      "epochs 965/1000:\n",
      "training cost 4.441971763652517|validation cost 5.722655573562126\n",
      "b: 4.469398891339616\n",
      "epochs 966/1000:\n",
      "training cost 4.437888137913925|validation cost 5.718056227800583\n",
      "b: 4.4694060212066935\n",
      "epochs 967/1000:\n",
      "training cost 4.433813026914536|validation cost 5.713466048360425\n",
      "b: 4.469413087617954\n",
      "epochs 968/1000:\n",
      "training cost 4.429746406118546|validation cost 5.708885010687714\n",
      "b: 4.469420091138154\n",
      "epochs 969/1000:\n",
      "training cost 4.425688251081252|validation cost 5.7043130903124135\n",
      "b: 4.469427032327025\n",
      "epochs 970/1000:\n",
      "training cost 4.4216385374486284|validation cost 5.699750262848022\n",
      "b: 4.469433911739315\n",
      "epochs 971/1000:\n",
      "training cost 4.41759724095692|validation cost 5.695196503991228\n",
      "b: 4.469440729924835\n",
      "epochs 972/1000:\n",
      "training cost 4.4135643374322155|validation cost 5.690651789521541\n",
      "b: 4.4694474874285035\n",
      "epochs 973/1000:\n",
      "training cost 4.409539802790034|validation cost 5.68611609530094\n",
      "b: 4.46945418479039\n",
      "epochs 974/1000:\n",
      "training cost 4.405523613034925|validation cost 5.681589397273524\n",
      "b: 4.469460822545756\n",
      "epochs 975/1000:\n",
      "training cost 4.401515744260048|validation cost 5.677071671465157\n",
      "b: 4.469467401225098\n",
      "epochs 976/1000:\n",
      "training cost 4.397516172646775|validation cost 5.672562893983117\n",
      "b: 4.4694739213541945\n",
      "epochs 977/1000:\n",
      "training cost 4.393524874464279|validation cost 5.668063041015756\n",
      "b: 4.469480383454142\n",
      "epochs 978/1000:\n",
      "training cost 4.389541826069137|validation cost 5.663572088832151\n",
      "b: 4.4694867880414\n",
      "epochs 979/1000:\n",
      "training cost 4.385567003904929|validation cost 5.659090013781758\n",
      "b: 4.469493135627832\n",
      "epochs 980/1000:\n",
      "training cost 4.381600384501843|validation cost 5.654616792294071\n",
      "b: 4.469499426720744\n",
      "epochs 981/1000:\n",
      "training cost 4.377641944476275|validation cost 5.650152400878287\n",
      "b: 4.46950566182293\n",
      "epochs 982/1000:\n",
      "training cost 4.373691660530444|validation cost 5.645696816122959\n",
      "b: 4.4695118414327055\n",
      "epochs 983/1000:\n",
      "training cost 4.369749509451989|validation cost 5.641250014695666\n",
      "b: 4.469517966043955\n",
      "epochs 984/1000:\n",
      "training cost 4.365815468113595|validation cost 5.636811973342687\n",
      "b: 4.469524036146163\n",
      "epochs 985/1000:\n",
      "training cost 4.361889513472598|validation cost 5.632382668888644\n",
      "b: 4.469530052224463\n",
      "epochs 986/1000:\n",
      "training cost 4.357971622570604|validation cost 5.6279620782362\n",
      "b: 4.469536014759665\n",
      "epochs 987/1000:\n",
      "training cost 4.354061772533103|validation cost 5.623550178365707\n",
      "b: 4.469541924228304\n",
      "epochs 988/1000:\n",
      "training cost 4.350159940569096|validation cost 5.619146946334889\n",
      "b: 4.469547781102672\n",
      "epochs 989/1000:\n",
      "training cost 4.34626610397071|validation cost 5.614752359278518\n",
      "b: 4.469553585850858\n",
      "epochs 990/1000:\n",
      "training cost 4.342380240112827|validation cost 5.610366394408088\n",
      "b: 4.469559338936786\n",
      "epochs 991/1000:\n",
      "training cost 4.33850232645271|validation cost 5.605989029011486\n",
      "b: 4.469565040820248\n",
      "epochs 992/1000:\n",
      "training cost 4.334632340529629|validation cost 5.601620240452683\n",
      "b: 4.469570691956948\n",
      "epochs 993/1000:\n",
      "training cost 4.330770259964499|validation cost 5.597260006171406\n",
      "b: 4.469576292798531\n",
      "epochs 994/1000:\n",
      "training cost 4.326916062459496|validation cost 5.592908303682826\n",
      "b: 4.469581843792624\n",
      "epochs 995/1000:\n",
      "training cost 4.3230697257977155|validation cost 5.588565110577242\n",
      "b: 4.46958734538287\n",
      "epochs 996/1000:\n",
      "training cost 4.319231227842786|validation cost 5.584230404519766\n",
      "b: 4.4695927980089625\n",
      "epochs 997/1000:\n",
      "training cost 4.31540054653852|validation cost 5.579904163250008\n",
      "b: 4.469598202106683\n",
      "epochs 998/1000:\n",
      "training cost 4.311577659908559|validation cost 5.575586364581774\n",
      "b: 4.469603558107933\n",
      "epochs 999/1000:\n",
      "training cost 4.307762546056002|validation cost 5.571276986402748\n",
      "b: 4.4696088664407725\n",
      "epochs 1000/1000:\n",
      "training cost 4.303955183163061|validation cost 5.566976006674188\n",
      "b: 4.469614127529449\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w,b=linear_regression_model(X_train,Y_train,X_test,Y_test,0.0089,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in range(0,10000):\n",
    "    q=X_test.iloc[:,i]\n",
    "    r=np.dot(w,q)+b\n",
    "    y_pred.append(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.673870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.907849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.111101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.137610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  5.673870\n",
       "1  6.907849\n",
       "2  2.111101\n",
       "3  0.998609\n",
       "4  3.137610"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
